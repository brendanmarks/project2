{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "1109        0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "940         0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "192         0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "260         0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "1148        0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "835         0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1216        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1653        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "559         0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "684         0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
      "1109        0.0        0.0        0.0        0.0  ...       15.0        6.0   \n",
      "940         0.0        0.0        0.0        1.0  ...        8.0        0.0   \n",
      "192         3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "260         0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1148        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "835         0.0        0.0        0.0        2.0  ...        1.0        0.0   \n",
      "1216        2.0        0.0        0.0       11.0  ...        7.0        0.0   \n",
      "1653        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "559         4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "684         0.0        0.0        0.0        4.0  ...        1.0        0.0   \n",
      "\n",
      "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
      "1109        0.0        0.0        0.0        7.0       15.0       16.0   \n",
      "940         0.0        2.0       13.0       16.0       16.0       16.0   \n",
      "192         0.0        0.0       15.0       13.0        7.0        0.0   \n",
      "260         0.0        0.0        0.0       11.0        9.0        0.0   \n",
      "1148        0.0        0.0        0.0       12.0       12.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "835         0.0        1.0        9.0       12.0       13.0        9.0   \n",
      "1216        0.0        0.0       12.0       16.0       15.0        9.0   \n",
      "1653        0.0        0.0        9.0       13.0        0.0        0.0   \n",
      "559         0.0        0.0        6.0       16.0        4.0        0.0   \n",
      "684         0.0        0.0        5.0       16.0       16.0       11.0   \n",
      "\n",
      "      pixel_7_6  pixel_7_7  \n",
      "1109       16.0        6.0  \n",
      "940         2.0        0.0  \n",
      "192         0.0        0.0  \n",
      "260         0.0        0.0  \n",
      "1148        0.0        0.0  \n",
      "...         ...        ...  \n",
      "835         0.0        0.0  \n",
      "1216        1.0        0.0  \n",
      "1653        0.0        0.0  \n",
      "559         0.0        0.0  \n",
      "684         0.0        0.0  \n",
      "\n",
      "[1437 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "d = datasets.load_digits(as_frame=True)\n",
    "digits = d['data']\n",
    "digits_target = d['target']\n",
    "\n",
    "c = datasets.fetch_openml(name='credit-g', as_frame=True)\n",
    "credit = c['data']\n",
    "credit_target = c['target']\n",
    "\n",
    "digits, digits_test, digits_target, digits_target_test = train_test_split(digits, digits_target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "credit, credit_test, credit_target, credit_target_test = train_test_split(credit, credit_target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print (digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "1           0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "2           0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "3           0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "4           0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1433        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1434        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "1435        0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "1436        0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        6.0        0.0   \n",
      "1           0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
      "2           3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "3           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1432        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1433        2.0        0.0        0.0       11.0  ...        0.0        0.0   \n",
      "1434        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1435        4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1436        0.0        0.0        0.0        4.0  ...        0.0        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0           0.0        0.0        7.0       15.0       16.0       16.0   \n",
      "1           2.0       13.0       16.0       16.0       16.0        2.0   \n",
      "2           0.0       15.0       13.0        7.0        0.0        0.0   \n",
      "3           0.0        0.0       11.0        9.0        0.0        0.0   \n",
      "4           0.0        0.0       12.0       12.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        1.0        9.0       12.0       13.0        9.0        0.0   \n",
      "1433        0.0       12.0       16.0       15.0        9.0        1.0   \n",
      "1434        0.0        9.0       13.0        0.0        0.0        0.0   \n",
      "1435        0.0        6.0       16.0        4.0        0.0        0.0   \n",
      "1436        0.0        5.0       16.0       16.0       11.0        0.0   \n",
      "\n",
      "      pixel_7_7  target  \n",
      "0           6.0       6  \n",
      "1           0.0       5  \n",
      "2           0.0       3  \n",
      "3           0.0       4  \n",
      "4           0.0       4  \n",
      "...         ...     ...  \n",
      "1432        0.0       3  \n",
      "1433        0.0       3  \n",
      "1434        0.0       7  \n",
      "1435        0.0       7  \n",
      "1436        0.0       8  \n",
      "\n",
      "[1437 rows x 65 columns]\n",
      "     pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0          0.0        0.0       11.0       16.0       15.0        3.0   \n",
      "1          0.0        1.0       15.0       14.0        2.0        0.0   \n",
      "2          0.0        2.0       13.0       16.0       10.0        0.0   \n",
      "3          0.0        0.0        9.0        7.0        0.0        0.0   \n",
      "4          0.0        0.0        3.0       13.0        6.0        0.0   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "355        0.0        0.0        3.0        8.0       11.0       13.0   \n",
      "356        0.0        0.0        0.0        9.0       11.0        0.0   \n",
      "357        0.0        1.0        9.0       16.0       16.0       12.0   \n",
      "358        0.0        0.0        0.0        3.0       14.0       13.0   \n",
      "359        0.0        0.0        0.0        9.0       13.0       10.0   \n",
      "\n",
      "     pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0          0.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "1          0.0        0.0        0.0        6.0  ...        0.0        0.0   \n",
      "2          0.0        0.0        0.0       12.0  ...        0.0        0.0   \n",
      "3          0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "4          0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "355       14.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "356        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "357        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "358        3.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "359        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "\n",
      "     pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0          0.0       13.0       13.0        8.0       13.0       16.0   \n",
      "1          1.0       15.0       16.0       12.0        1.0        0.0   \n",
      "2          1.0       13.0       16.0       16.0       16.0       16.0   \n",
      "3          0.0        7.0       14.0       16.0       12.0        1.0   \n",
      "4          0.0        3.0       13.0       15.0        8.0        0.0   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "355        0.0        2.0       12.0       13.0        2.0        0.0   \n",
      "356        0.0        0.0       11.0        7.0        0.0        0.0   \n",
      "357        0.0       10.0       16.0       11.0        4.0        0.0   \n",
      "358        0.0        0.0        3.0       13.0       15.0        2.0   \n",
      "359        0.0        0.0       10.0       16.0       12.0        0.0   \n",
      "\n",
      "     pixel_7_7  target  \n",
      "0          8.0       2  \n",
      "1          0.0       8  \n",
      "2          3.0       2  \n",
      "3          0.0       6  \n",
      "4          0.0       6  \n",
      "..         ...     ...  \n",
      "355        0.0       5  \n",
      "356        0.0       4  \n",
      "357        0.0       3  \n",
      "358        0.0       8  \n",
      "359        0.0       8  \n",
      "\n",
      "[360 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# no preprocessing needed \n",
    "\n",
    "digits_final = pd.concat([digits, digits_target], axis=1)\n",
    "digits_final.reset_index(drop=True, inplace=True)\n",
    "print (digits_final)\n",
    "\n",
    "digits_test_final = pd.concat([digits_test, digits_target_test], axis=1)\n",
    "digits_test_final.reset_index(drop=True, inplace=True)\n",
    "print (digits_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0    0.500000       0.155341                    1.00             0.75   \n",
      "1    0.333333       0.169507                    1.00             0.25   \n",
      "2    0.833333       0.402084                    1.00             0.50   \n",
      "3    0.208333       0.068606                    0.50             0.50   \n",
      "4    0.083333       0.084347                    0.25             0.50   \n",
      "..        ...            ...                     ...              ...   \n",
      "795  0.166667       0.058728                    1.00             1.00   \n",
      "796  0.375000       0.212495                    1.00             0.50   \n",
      "797  0.125000       0.207990                    0.25             1.00   \n",
      "798  0.250000       0.104646                    0.50             0.50   \n",
      "799  0.500000       0.535009                    0.25             0.75   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.400000              0.25             0.5                0        4   \n",
      "1    0.360000              0.25             0.5                1        4   \n",
      "2    0.320000              0.25             0.5                0        4   \n",
      "3    0.333333              0.25             0.5                0        4   \n",
      "4    0.320000              0.50             0.5                3        6   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "795  0.640000              0.50             0.5                1        4   \n",
      "796  0.480000              0.25             1.0                0        0   \n",
      "797  0.853333              0.25             0.5                3        2   \n",
      "798  0.413333              0.50             0.5                0        3   \n",
      "799  0.413333              0.50             1.0                0        0   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 2  ...           3                3              2   \n",
      "1                 3  ...           2                0              2   \n",
      "2                 3  ...           2                0              2   \n",
      "3                 0  ...           0                2              2   \n",
      "4                 1  ...           1                0              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "795               4  ...           0                3              2   \n",
      "796               3  ...           0                3              2   \n",
      "797               3  ...           3                3              2   \n",
      "798               1  ...           2                3              2   \n",
      "799               2  ...           1                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     2                    1        0    1              0   \n",
      "1                     1                    1        1    1              0   \n",
      "2                     1                    1        1    0              0   \n",
      "3                     1                    1        2    1              0   \n",
      "4                     0                    1        2    1              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "795                   0                    0        1    1              0   \n",
      "796                   0                    1        1    1              1   \n",
      "797                   3                    1        1    3              0   \n",
      "798                   3                    1        1    3              0   \n",
      "799                   1                    1        1    3              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 1      0  \n",
      "2                 1      0  \n",
      "3                 1      0  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "795               1      0  \n",
      "796               1      0  \n",
      "797               1      1  \n",
      "798               1      0  \n",
      "799               1      1  \n",
      "\n",
      "[800 rows x 21 columns]\n",
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0        0.60       0.272003                    1.00             0.75   \n",
      "1        0.15       0.245757                    0.25             0.50   \n",
      "2        0.30       0.172793                    0.75             1.00   \n",
      "3        0.20       0.137066                    1.00             0.25   \n",
      "4        1.00       0.712195                    0.50             1.00   \n",
      "..        ...            ...                     ...              ...   \n",
      "195      0.30       0.099828                    0.75             0.25   \n",
      "196      0.20       0.084370                    1.00             0.50   \n",
      "197      0.10       0.064033                    0.25             0.75   \n",
      "198      0.60       0.555548                    0.50             1.00   \n",
      "199      0.10       0.092477                    0.50             1.00   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.461538              0.25             0.5                1        3   \n",
      "1    0.400000              0.25             1.0                3        4   \n",
      "2    0.661538              0.25             0.5                3        3   \n",
      "3    0.415385              0.25             0.5                0        4   \n",
      "4    0.646154              0.25             0.5                3        4   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "195  0.400000              0.25             0.5                3        6   \n",
      "196  0.369231              0.25             0.5                1        4   \n",
      "197  0.600000              0.50             0.5                0        8   \n",
      "198  0.646154              1.00             0.5                0        4   \n",
      "199  0.646154              0.25             1.0                3        6   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 3  ...           4                3              2   \n",
      "1                 3  ...           0                3              1   \n",
      "2                 3  ...           0                3              2   \n",
      "3                 1  ...           2                3              2   \n",
      "4                 3  ...           3                3              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "195               3  ...           2                0              2   \n",
      "196               3  ...           0                0              2   \n",
      "197               1  ...           1                0              2   \n",
      "198               2  ...           3                3              2   \n",
      "199               3  ...           3                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     1                    1        1    0              1   \n",
      "1                     3                    1        2    1              0   \n",
      "2                     3                    1        1    1              1   \n",
      "3                     0                    1        1    1              0   \n",
      "4                     1                    1        1    0              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "195                   3                    1        1    1              0   \n",
      "196                   3                    1        1    3              0   \n",
      "197                   1                    1        1    3              0   \n",
      "198                   0                    1        1    0              1   \n",
      "199                   2                    0        0    1              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 0      1  \n",
      "2                 1      1  \n",
      "3                 1      1  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "195               1      1  \n",
      "196               1      0  \n",
      "197               1      1  \n",
      "198               1      0  \n",
      "199               1      1  \n",
      "\n",
      "[200 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#everything good with data except categorical to one hot needed \n",
    "credit_cat = ['checking_status', 'purpose', 'credit_history', 'savings_status', 'employment', 'personal_status', 'other_parties',\n",
    "             'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker', 'class']\n",
    "\n",
    "def extract_columns (df, cols):\n",
    "    return df.loc[:, cols]\n",
    "\n",
    "def get_onehot (df, cat_feat):\n",
    "    categories = extract_columns(df, cat_feat)\n",
    "    le = LabelEncoder()\n",
    "    return categories.apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "merged_credit = pd.concat([credit, credit_target], axis=1)\n",
    "merged_credit.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merged_credit_test = pd.concat([credit_test, credit_target_test], axis=1)\n",
    "merged_credit_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "one_hot_cols = get_onehot(merged_credit, credit_cat)\n",
    "credit_no_cat = merged_credit.drop(credit_cat, axis = 1) \n",
    "credit_no_cat = credit_no_cat.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x))) #normalize continuous data\n",
    "credit_final = pd.concat([credit_no_cat, one_hot_cols], axis=1)\n",
    "\n",
    "\n",
    "one_hot_cols_test = get_onehot(merged_credit_test, credit_cat)\n",
    "credit_test_no_cat = merged_credit_test.drop(credit_cat, axis=1)\n",
    "credit_test_no_cat = credit_test_no_cat.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "credit_test_final = pd.concat([credit_test_no_cat, one_hot_cols_test], axis=1)\n",
    "\n",
    "#le = LabelEncoder()\n",
    "\n",
    "#credit_target = le.fit_transform(credit_target)\n",
    "#credit_target_test = le.fit_transform(credit_target_test)\n",
    "\n",
    "print (credit_final)\n",
    "print (credit_test_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optimizer class implementing minibatch gradient descent for softmax regression. Can utilize either\n",
    "    gradient descent with momentum, or Adaptive Momentum Estimation (Adam), with optional L1 or L2\n",
    "    regularization.\n",
    "\"\"\"\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "# Softmax of input z\n",
    "def softmax(z):\n",
    "    return np.exp(z) / sum(np.exp(z))\n",
    "\n",
    "\n",
    "# Shuffles the (x,y) instances, and outputs a list of minibatch_size sized (x,y) tuples\n",
    "def minibatch(x, y, minibatch_size):\n",
    "    x, y = shuffle(x, y)\n",
    "    minibatches = []\n",
    "    if not minibatch_size:\n",
    "        minibatches.append((x, y))\n",
    "    else:\n",
    "        for i in range(0, x.shape[0], minibatch_size):\n",
    "            x_mini = x[i:i+minibatch_size]\n",
    "            y_mini = y[i:i+minibatch_size]\n",
    "            minibatches.append((x_mini, y_mini))\n",
    "    return minibatches\n",
    "\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(y, yh):\n",
    "    pred = np.argmax(yh, axis=1)\n",
    "    y_int = y.astype(np.int64)\n",
    "    return np.mean(np.array_equal(pred, y_int))\n",
    "\n",
    "\n",
    "# Returns the index of the maximum value in a list\n",
    "def argmax(lst):\n",
    "    return lst.index(max(lst))\n",
    "\n",
    "\n",
    "class GradientDescent:\n",
    "\n",
    "    \"\"\"\n",
    "    Class fields:\n",
    "       alphaa - learning rate of the optimizer\n",
    "       beta1 - momentum hyperparameter\n",
    "       max_iterations - gradient descent termination condition: maximum times iterated\n",
    "       max_no_change - gradient descent termination condition: maximum number of iterations\n",
    "                         without the validation error decreasing\n",
    "       minibatch_size - size of the minibatch to use (default value of 0 indicates use full batch)\n",
    "       cost_fn - optional cost function, if included optimizer will calculate and store the\n",
    "                    training and validation cost at each iteration\n",
    "       adaptive - if true, optimizer uses Adam (Adaptive Moment Estimation) rather than gradient\n",
    "                    descent with momentum\n",
    "       beta2 - 2nd hyperparameter for Adam (if using)\n",
    "       epsilon - 3rd hyperparameter for Adam (if using), just to avoid numerical issues\n",
    "       regularize - determines regularization used (if any): 0 indicates no regularization, 1 or 2\n",
    "                      indicate L1 or L2 regularization respectively\n",
    "       lambdaa - regularization coefficient if used\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(self, alphaa=0.01, beta1=0.9, max_iterations=1e4, max_no_change=20, minibatch_size=0,\n",
    "                 cost_fn=None, adaptive=False, beta2=0.999, epsilon=1e-8, regularize=0, lambdaa=0.1):\n",
    "\n",
    "        self.alphaa = alphaa\n",
    "        self.beta1 = beta1\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_no_change = max_no_change\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.cost_fn = cost_fn\n",
    "\n",
    "        self.adaptive = adaptive\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.regularize = regularize\n",
    "        self.lambdaa = lambdaa\n",
    "\n",
    "        self.accuracy_tr = []\n",
    "        self.accuracy_val = []\n",
    "        self.weight_history = []\n",
    "        if self.cost_fn:\n",
    "            self.cost_tr = []\n",
    "            self.cost_val = []\n",
    "\n",
    "    # Run method - delegates work to one of 2 helper methods, dependent on if Adam is being used or not\n",
    "    def run(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        if self.adaptive:\n",
    "            return self.adam(x_tr, y_tr, x_val, y_val, w)\n",
    "        else:\n",
    "            return self.momentum(x_tr, y_tr, x_val, y_val, w)\n",
    "\n",
    "    # Gradient Descent with Momentum\n",
    "    def momentum(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        t = 1\n",
    "        i = 0\n",
    "        delta_w = 0\n",
    "\n",
    "        self.accuracy_tr.append(accuracy(y_tr, softmax(np.dot(x_tr, w))))\n",
    "        self.accuracy_val.append(accuracy(y_val, softmax(np.dot(x_val, w))))\n",
    "\n",
    "        while i < self.max_no_change and t < self.max_iterations:\n",
    "            for (x_mini, y_mini) in minibatch(x_tr, y_tr, self.minibatch_size):\n",
    "                grad = self.gradient(x_mini, y_mini, w)\n",
    "                delta_w = (self.beta1 * delta_w) + ((1 - self.beta1) * grad)\n",
    "                w -= self.alphaa * delta_w\n",
    "\n",
    "            self.weight_history.append(w)\n",
    "            tr_pred = softmax(np.dot(x_tr, w))\n",
    "            pred = softmax(np.dot(x_val, w))\n",
    "            self.accuracy_tr.append(accuracy(y_tr, tr_pred))\n",
    "            self.accuracy_val.append(accuracy(y_val, pred))\n",
    "            if self.cost_fn:\n",
    "                self.cost_tr.append(self.cost_fn(y_tr, tr_pred))\n",
    "                self.cost_val.append(self.cost_fn(y_val, pred))\n",
    "\n",
    "            if not self.accuracy_val[-1] < self.accuracy_val[-2]:\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "            t += 1\n",
    "\n",
    "        return self.weight_history[argmax(self.accuracy_val)]\n",
    "\n",
    "    # Adaptive Moment Estimation\n",
    "    def adam(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        t = 1\n",
    "        i = 0\n",
    "        m = 0\n",
    "        s = 0\n",
    "\n",
    "        self.accuracy_tr.append(accuracy(y_tr, softmax(np.dot(x_tr, w))))\n",
    "        self.accuracy_val.append(accuracy(y_val, softmax(np.dot(x_val, w))))\n",
    "\n",
    "        while i < self.max_no_change and t < self.max_iterations:\n",
    "            for (x_mini, y_mini) in minibatch(x_tr, y_tr, self.minibatch_size):\n",
    "                grad = self.gradient(x_mini, y_mini, w)\n",
    "                m = (self.beta1 * m) + ((1 - self.beta1) * grad)\n",
    "                s = (self.beta2 * s) + ((1 - self.beta2) * np.power(grad, 2))\n",
    "                mh = m / (1 - np.power(self.beta1, t))\n",
    "                sh = s / (1 - np.power(self.beta2, t))\n",
    "                w -= self.alphaa * mh * grad / (np.sqrt(sh) + self.epsilon)\n",
    "\n",
    "            self.weight_history.append(w)\n",
    "            tr_pred = softmax(np.dot(x_tr, w))\n",
    "            pred = softmax(np.dot(x_val, w))\n",
    "            self.accuracy_tr.append(accuracy(y_tr, tr_pred))\n",
    "            self.accuracy_val.append(accuracy(y_val, pred))\n",
    "            if self.cost_fn:\n",
    "                self.cost_tr.append(self.cost_fn(y_tr, tr_pred))\n",
    "                self.cost_val.append(self.cost_fn(y_val, pred))\n",
    "\n",
    "            if not self.accuracy_val[-1] < self.accuracy_val[-2]:\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "            t += 1\n",
    "\n",
    "        return self.weight_history[argmax(self.accuracy_val)]\n",
    "\n",
    "    # Helper method to calculate gradient (and add regularization penalty if any)\n",
    "    def gradient(self, x, y, w):\n",
    "        n, d = x.shape\n",
    "        yh = softmax(np.dot(x, w))\n",
    "\n",
    "        grad = np.dot(x.T, yh - y) / n\n",
    "        if self.regularize == 1:\n",
    "            grad[1:] += self.lambdaa * np.sign(w[1:])\n",
    "        elif self.regularize == 2:\n",
    "            grad[1:] += self.lambdaa * w[1:]\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from .._base import _BaseClassifier\n",
    "#from .._base import _BaseMultiClass\n",
    "\n",
    "\n",
    "class SoftmaxRegression(object):\n",
    "\n",
    "    \"\"\"Softmax regression classifier.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, epochs=50,\n",
    "                 l2=0.0,\n",
    "                 minibatches=1,\n",
    "                 n_classes=None,\n",
    "                 random_seed=None):\n",
    "\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        self.l2 = l2\n",
    "        self.minibatches = minibatches\n",
    "        self.n_classes = n_classes\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "\n",
    "    def fit(self, X, y, gd):\n",
    "        \n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "  \n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = np.max(y) + 1\n",
    "        self._n_features = X.shape[1]\n",
    "\n",
    "\n",
    "        \"\"\"Initialize weight coefficients.\"\"\"\n",
    "        np.random.seed(self.random_seed)\n",
    "        self.w_ = np.random.normal(loc=0.0, scale=0.01, size=(self._n_features, self.n_classes)).astype('float64')\n",
    "        self.cost_ = []\n",
    "\n",
    "        y_enc = self._one_hot(y=y, n_labels=self.n_classes, dtype=np.float)\n",
    "     \n",
    "        for i in range(self.epochs):\n",
    "           \n",
    "            \n",
    "            #GRADIENT DESCENT line below (make sure to split X, y into training and validation sets)\n",
    "            \n",
    "            self._w = gd.run(X,y_enc,X,y_enc,self.w_)\n",
    "            \n",
    "            #COMMENT THE FOR LOOP BELOW\n",
    "\n",
    "            \"\"\" \n",
    "            for idx in self._yield_minibatches_idx(\n",
    "                    n_batches=self.minibatches,\n",
    "                    data_ary=y,\n",
    "                    shuffle=True):\n",
    "                # givens:\n",
    "                # w_ -> n_feat x n_classes\n",
    "                # b_  -> n_classes\n",
    "                \n",
    "                # net_input, softmax and diff -> n_samples x n_classes:\n",
    "                net = X[idx].dot(self.w_) #net_input\n",
    "                softm = self.softmax(net) \n",
    "                diff = softm - y_enc[idx]\n",
    "                mse = np.mean(diff, axis=0)\n",
    "\n",
    "                # gradient -> n_features x n_classes\n",
    "                grad = np.dot(X[idx].T, diff)\n",
    "                \n",
    "                # update in opp. direction of the cost gradient\n",
    "                self.w_ -= (self.eta * grad +\n",
    "                            self.eta * self.l2 * self.w_)  \n",
    "            \n",
    "            \"\"\"  \n",
    "            # compute cost of the whole epoch\n",
    "            net = X.dot(self.w_)\n",
    "            softm = self.softmax(net)\n",
    "            cross_ent = self.cross_entropy(output=softm, y_target=y_enc)\n",
    "            cost = self.cost(cross_ent)\n",
    "            self.cost_.append(cost)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        #Predict targets from X.\n",
    "\n",
    "        net = X.dot(self.w_)\n",
    "        probas = self.softmax(net)\n",
    "        return probas.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
    "\n",
    "\n",
    "    def cross_entropy(self, output, y_target):\n",
    "        return - np.sum(np.log(output) * (y_target), axis=1)\n",
    "\n",
    "    def cost(self, cross_entropy):\n",
    "        L2_term = self.l2 * np.sum(self.w_ ** 2)\n",
    "        cross_entropy = cross_entropy + L2_term\n",
    "        return 0.5 * np.mean(cross_entropy)\n",
    "\n",
    "\n",
    "    def _one_hot(self, y, n_labels, dtype):\n",
    "        mat = np.zeros((len(y), n_labels))\n",
    "        for i, val in enumerate(y):\n",
    "            mat[i, val] = 1\n",
    "        return mat.astype(dtype)    \n",
    "    \n",
    "    def _yield_minibatches_idx(self, n_batches, data_ary, shuffle=True):\n",
    "            indices = np.arange(data_ary.shape[0])\n",
    "\n",
    "            if shuffle:\n",
    "                indices = np.random.permutation(indices)\n",
    "            if n_batches > 1:\n",
    "                remainder = data_ary.shape[0] % n_batches\n",
    "\n",
    "                if remainder:\n",
    "                    minis = np.array_split(indices[:-remainder], n_batches)\n",
    "                    minis[-1] = np.concatenate((minis[-1],\n",
    "                                                indices[-remainder:]),\n",
    "                                               axis=0)\n",
    "                else:\n",
    "                    minis = np.array_split(indices, n_batches)\n",
    "\n",
    "            else:\n",
    "                minis = (indices,)\n",
    "\n",
    "            for idx_batch in minis:\n",
    "                yield idx_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ... 16. 16.  6.]\n",
      " [ 0.  3. 12. ... 16.  2.  0.]\n",
      " [ 0.  1. 10. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  4. ...  0.  0.  0.]\n",
      " [ 0.  0.  6. ... 11.  0.  0.]]\n",
      "       0    1     2     3     4     5    6    7    8     9   ...    54   55  \\\n",
      "0     0.0  0.0   0.0   9.0  15.0   2.0  0.0  0.0  0.0   0.0  ...  15.0  6.0   \n",
      "1     0.0  3.0  12.0  12.0  14.0   4.0  0.0  0.0  0.0   1.0  ...   8.0  0.0   \n",
      "2     0.0  1.0  10.0  15.0  16.0  13.0  3.0  0.0  0.0   5.0  ...   0.0  0.0   \n",
      "3     0.0  0.0   0.0  12.0   4.0   0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
      "4     0.0  0.0   0.0   9.0  16.0   3.0  0.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
      "...   ...  ...   ...   ...   ...   ...  ...  ...  ...   ...  ...   ...  ...   \n",
      "1432  0.0  1.0   8.0  14.0  15.0   2.0  0.0  0.0  0.0   2.0  ...   1.0  0.0   \n",
      "1433  0.0  2.0   9.0  15.0  16.0  15.0  2.0  0.0  0.0  11.0  ...   7.0  0.0   \n",
      "1434  0.0  0.0   5.0  14.0  14.0   2.0  0.0  0.0  0.0   2.0  ...   0.0  0.0   \n",
      "1435  0.0  0.0   4.0  10.0  15.0  16.0  4.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
      "1436  0.0  0.0   6.0  14.0  13.0   4.0  0.0  0.0  0.0   4.0  ...   1.0  0.0   \n",
      "\n",
      "       56   57    58    59    60    61    62   63  \n",
      "0     0.0  0.0   0.0   7.0  15.0  16.0  16.0  6.0  \n",
      "1     0.0  2.0  13.0  16.0  16.0  16.0   2.0  0.0  \n",
      "2     0.0  0.0  15.0  13.0   7.0   0.0   0.0  0.0  \n",
      "3     0.0  0.0   0.0  11.0   9.0   0.0   0.0  0.0  \n",
      "4     0.0  0.0   0.0  12.0  12.0   0.0   0.0  0.0  \n",
      "...   ...  ...   ...   ...   ...   ...   ...  ...  \n",
      "1432  0.0  1.0   9.0  12.0  13.0   9.0   0.0  0.0  \n",
      "1433  0.0  0.0  12.0  16.0  15.0   9.0   1.0  0.0  \n",
      "1434  0.0  0.0   9.0  13.0   0.0   0.0   0.0  0.0  \n",
      "1435  0.0  0.0   6.0  16.0   4.0   0.0   0.0  0.0  \n",
      "1436  0.0  0.0   5.0  16.0  16.0  11.0   0.0  0.0  \n",
      "\n",
      "[1437 rows x 64 columns]\n",
      "       0      1       2       3       4       5       6    7    8       9   \\\n",
      "0     0.0  0.000  0.0000  0.5625  0.9375  0.1250  0.0000  0.0  0.0  0.0000   \n",
      "1     0.0  0.375  0.7500  0.7500  0.8750  0.2500  0.0000  0.0  0.0  0.0625   \n",
      "2     0.0  0.125  0.6250  0.9375  1.0000  0.8125  0.1875  0.0  0.0  0.3125   \n",
      "3     0.0  0.000  0.0000  0.7500  0.2500  0.0000  0.0000  0.0  0.0  0.0000   \n",
      "4     0.0  0.000  0.0000  0.5625  1.0000  0.1875  0.0000  0.0  0.0  0.0000   \n",
      "...   ...    ...     ...     ...     ...     ...     ...  ...  ...     ...   \n",
      "1432  0.0  0.125  0.5000  0.8750  0.9375  0.1250  0.0000  0.0  0.0  0.1250   \n",
      "1433  0.0  0.250  0.5625  0.9375  1.0000  0.9375  0.1250  0.0  0.0  0.6875   \n",
      "1434  0.0  0.000  0.3125  0.8750  0.8750  0.1250  0.0000  0.0  0.0  0.1250   \n",
      "1435  0.0  0.000  0.2500  0.6250  0.9375  1.0000  0.2500  0.0  0.0  0.0000   \n",
      "1436  0.0  0.000  0.3750  0.8750  0.8125  0.2500  0.0000  0.0  0.0  0.2500   \n",
      "\n",
      "      ...      54        55   56        57      58      59      60      61  \\\n",
      "0     ...  0.9375  0.461538  0.0  0.000000  0.0000  0.4375  0.9375  1.0000   \n",
      "1     ...  0.5000  0.000000  0.0  0.222222  0.8125  1.0000  1.0000  1.0000   \n",
      "2     ...  0.0000  0.000000  0.0  0.000000  0.9375  0.8125  0.4375  0.0000   \n",
      "3     ...  0.0000  0.000000  0.0  0.000000  0.0000  0.6875  0.5625  0.0000   \n",
      "4     ...  0.0000  0.000000  0.0  0.000000  0.0000  0.7500  0.7500  0.0000   \n",
      "...   ...     ...       ...  ...       ...     ...     ...     ...     ...   \n",
      "1432  ...  0.0625  0.000000  0.0  0.111111  0.5625  0.7500  0.8125  0.5625   \n",
      "1433  ...  0.4375  0.000000  0.0  0.000000  0.7500  1.0000  0.9375  0.5625   \n",
      "1434  ...  0.0000  0.000000  0.0  0.000000  0.5625  0.8125  0.0000  0.0000   \n",
      "1435  ...  0.0000  0.000000  0.0  0.000000  0.3750  1.0000  0.2500  0.0000   \n",
      "1436  ...  0.0625  0.000000  0.0  0.000000  0.3125  1.0000  1.0000  0.6875   \n",
      "\n",
      "          62     63  \n",
      "0     1.0000  0.375  \n",
      "1     0.1250  0.000  \n",
      "2     0.0000  0.000  \n",
      "3     0.0000  0.000  \n",
      "4     0.0000  0.000  \n",
      "...      ...    ...  \n",
      "1432  0.0000  0.000  \n",
      "1433  0.0625  0.000  \n",
      "1434  0.0000  0.000  \n",
      "1435  0.0000  0.000  \n",
      "1436  0.0000  0.000  \n",
      "\n",
      "[1437 rows x 64 columns]\n",
      "[6 5 3 ... 7 7 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading Data\n",
    "\n",
    "#X = one_hot_cols.values\n",
    "#y = credit_target.values\n",
    "\n",
    "X = digits.values\n",
    "y = digits_target.values\n",
    "\n",
    "print (X)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "print (df)\n",
    "df = df.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "\n",
    "print (df)\n",
    "#standardize\n",
    "# X[:,0] = X[:,0] / np.amax(X[:,0])\n",
    "# X[:,1] = X[:,1] / np.amax(X[:,1])\n",
    "\n",
    "print (y)\n",
    "\n",
    "lr = SoftmaxRegression(eta=0.00001, epochs=250, minibatches=1, random_seed=0)\n",
    "gd = GradientDescent()\n",
    "lr.fit(df.to_numpy(), y, gd)\n",
    "\n",
    "# #X_plt = X[:, [0,1]]\n",
    "\n",
    "# #plot_decision_regions(X_plt, y, clf=lr)\n",
    "# #plt.title('Softmax Regression - Gradient Descent')\n",
    "# #plt.show()\n",
    "\n",
    "plt.plot(range(len(lr.cost_)), lr.cost_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5, 2, 8, 6, 6, 6, 6, 1, 0, 5, 8, 8, 7,\n",
       "       8, 4, 7, 5, 4, 9, 2, 9, 4, 7, 6, 8, 9, 4, 3, 1, 0, 1, 8, 6, 7, 7,\n",
       "       1, 0, 7, 6, 2, 1, 9, 6, 7, 9, 0, 0, 5, 1, 6, 3, 0, 2, 3, 4, 1, 9,\n",
       "       2, 6, 9, 1, 8, 3, 5, 1, 2, 8, 2, 2, 9, 7, 2, 3, 6, 0, 5, 3, 7, 5,\n",
       "       1, 2, 9, 9, 3, 1, 7, 7, 4, 8, 5, 8, 5, 5, 2, 5, 9, 0, 7, 1, 4, 7,\n",
       "       3, 4, 8, 9, 7, 9, 8, 2, 6, 5, 2, 5, 8, 4, 8, 7, 0, 6, 1, 5, 9, 9,\n",
       "       9, 5, 9, 9, 5, 7, 5, 6, 2, 8, 6, 9, 6, 1, 5, 1, 5, 9, 9, 1, 5, 3,\n",
       "       6, 1, 8, 9, 8, 7, 6, 7, 6, 5, 6, 0, 8, 8, 9, 8, 6, 1, 0, 4, 1, 6,\n",
       "       3, 8, 6, 7, 4, 5, 6, 3, 0, 3, 3, 3, 0, 7, 7, 5, 7, 8, 0, 7, 8, 9,\n",
       "       6, 4, 5, 0, 1, 4, 6, 4, 3, 3, 0, 9, 5, 9, 2, 1, 4, 2, 1, 6, 8, 9,\n",
       "       2, 4, 9, 3, 7, 6, 2, 3, 3, 1, 6, 9, 3, 6, 3, 2, 2, 0, 7, 6, 1, 1,\n",
       "       9, 7, 2, 7, 8, 5, 5, 7, 5, 2, 3, 7, 2, 7, 5, 5, 7, 0, 9, 1, 6, 5,\n",
       "       9, 7, 4, 3, 8, 0, 3, 6, 4, 6, 3, 2, 6, 8, 8, 8, 4, 6, 7, 5, 2, 4,\n",
       "       5, 3, 2, 4, 6, 9, 4, 5, 4, 3, 4, 6, 2, 9, 0, 1, 7, 2, 0, 9, 6, 0,\n",
       "       4, 2, 0, 7, 9, 8, 5, 4, 8, 2, 8, 4, 3, 7, 2, 6, 9, 1, 5, 1, 0, 8,\n",
       "       2, 1, 9, 5, 6, 8, 2, 7, 2, 1, 5, 1, 6, 4, 5, 0, 9, 4, 1, 1, 7, 0,\n",
       "       8, 9, 0, 5, 4, 3, 8, 8])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_target_test.values[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 2 Class Labels: [2 8 2 6 6 7 1 3 3 5 2 1 6 6 6 6 1 0 5 3 3 7 3 4 7 5 4 3 2 3 4 7 6 1 3 4 3\n",
      " 1 0 1 1 6 7 7 3 0 1 0 2 1 3 6 7 3 0 0 0 1 6 3 0 2 3 4 1 3 7 6 0 1 1 3 5 1\n",
      " 2 1 2 1 3 7 2 3 6 0 0 3 7 5 1 2 0 4 3 1 1 7 4 1 5 1 5 5 2 5 3 0 4 1 4 1 3\n",
      " 4 1 3 7 7 1 0 1 3 3 5 3 4 1 4 0 6 1 5 3 3 3 5 3 3 5 7 3 6 2 3 6 9 6 1 5 1\n",
      " 5 3 3 1 0 3 6 1 0 4 1 7 6 1 6 5 6 0 1 1 3 3 6 1 0 4 1 6 3 3 6 7 4 3 6 3 0\n",
      " 3 3 3 0 4 7 0 7 1 0 7 1 3 6 4 5 0 1 4 6 4 3 3 0 3 5 3 3 1 4 1 1 4 1 3 3 4\n",
      " 3 3 1 6 2 3 3 1 6 3 3 6 3 3 2 0 7 6 1 1 3 7 3 7 1 3 3 7 5 3 3 7 2 7 0 5 7\n",
      " 0 3 1 6 5 3 7 4 3 3 0 3 6 4 0 3 3 6 3 8 1 4 6 7 5 2 4 5 3 2 4 6 3 4 5 4 3\n",
      " 4 6 2 3 0 1 7 2 0 3 6 0 4 1 0 7 1 8 4 7 8 2 3 4 3 7 2 6 1 1 4 1 0 3 2 1 3\n",
      " 5 6 0 3 7 3 1 5 1 6 4 5 0 3 4 1 1 7 0 1 3 0 5 4 3 1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-1164cb3e318c>:91: RuntimeWarning: overflow encountered in exp\n",
      "  return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
      "<ipython-input-56-1164cb3e318c>:91: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = lr.predict(digits_test.values)\n",
    "print('Last 2 Class Labels: %s' % y_pred[0:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.15534086 1.         ... 1.         0.         1.        ]\n",
      " [0.33333333 0.16950716 1.         ... 1.         0.         1.        ]\n",
      " [0.83333333 0.40208424 1.         ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.125      0.20798958 0.25       ... 3.         0.         1.        ]\n",
      " [0.25       0.10464611 0.5        ... 3.         0.         1.        ]\n",
      " [0.5        0.53500868 0.25       ... 3.         1.         1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-8b49741613d4>:15: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z) / sum(np.exp(z))\n",
      "<ipython-input-55-8b49741613d4>:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(z) / sum(np.exp(z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0    0.500000       0.155341                    1.00             0.75   \n",
      "1    0.333333       0.169507                    1.00             0.25   \n",
      "2    0.833333       0.402084                    1.00             0.50   \n",
      "3    0.208333       0.068606                    0.50             0.50   \n",
      "4    0.083333       0.084347                    0.25             0.50   \n",
      "..        ...            ...                     ...              ...   \n",
      "795  0.166667       0.058728                    1.00             1.00   \n",
      "796  0.375000       0.212495                    1.00             0.50   \n",
      "797  0.125000       0.207990                    0.25             1.00   \n",
      "798  0.250000       0.104646                    0.50             0.50   \n",
      "799  0.500000       0.535009                    0.25             0.75   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.400000              0.25             0.5                0        4   \n",
      "1    0.360000              0.25             0.5                1        4   \n",
      "2    0.320000              0.25             0.5                0        4   \n",
      "3    0.333333              0.25             0.5                0        4   \n",
      "4    0.320000              0.50             0.5                3        6   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "795  0.640000              0.50             0.5                1        4   \n",
      "796  0.480000              0.25             1.0                0        0   \n",
      "797  0.853333              0.25             0.5                3        2   \n",
      "798  0.413333              0.50             0.5                0        3   \n",
      "799  0.413333              0.50             1.0                0        0   \n",
      "\n",
      "     credit_history  savings_status  employment  personal_status  \\\n",
      "0                 2               0           3                3   \n",
      "1                 3               2           2                0   \n",
      "2                 3               0           2                0   \n",
      "3                 0               0           0                2   \n",
      "4                 1               2           1                0   \n",
      "..              ...             ...         ...              ...   \n",
      "795               4               2           0                3   \n",
      "796               3               2           0                3   \n",
      "797               3               4           3                3   \n",
      "798               1               2           2                3   \n",
      "799               2               0           1                3   \n",
      "\n",
      "     other_parties  property_magnitude  other_payment_plans  housing  job  \\\n",
      "0                2                   2                    1        0    1   \n",
      "1                2                   1                    1        1    1   \n",
      "2                2                   1                    1        1    0   \n",
      "3                2                   1                    1        2    1   \n",
      "4                2                   0                    1        2    1   \n",
      "..             ...                 ...                  ...      ...  ...   \n",
      "795              2                   0                    0        1    1   \n",
      "796              2                   0                    1        1    1   \n",
      "797              2                   3                    1        1    3   \n",
      "798              2                   3                    1        1    3   \n",
      "799              2                   1                    1        1    3   \n",
      "\n",
      "     own_telephone  foreign_worker  \n",
      "0                0               1  \n",
      "1                0               1  \n",
      "2                0               1  \n",
      "3                0               1  \n",
      "4                1               1  \n",
      "..             ...             ...  \n",
      "795              0               1  \n",
      "796              1               1  \n",
      "797              0               1  \n",
      "798              0               1  \n",
      "799              1               1  \n",
      "\n",
      "[800 rows x 20 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Loading Data\n",
    "\n",
    "#X = one_hot_cols.values\n",
    "#y = credit_target.values\n",
    "\n",
    "\n",
    "A = one_hot_cols.values\n",
    "b = credit_target\n",
    "\n",
    "# standardize\n",
    "#X[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()\n",
    "#X[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()\n",
    "\n",
    "x_train = credit_final.loc[:,credit_final.columns != \"class\"]\n",
    "y_train = credit_final.loc[:,credit_final.columns == \"class\"]\n",
    "\n",
    "print (x_train.to_numpy())\n",
    "\n",
    "# df = pd.DataFrame(x_train)\n",
    "# df = df.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "\n",
    "lr2 = SoftmaxRegression(eta=0.00001, epochs=250, minibatches=1, random_seed=0)\n",
    "gd = GradientDescent()\n",
    "lr2.fit(x_train.to_numpy(), y_train.values.ravel(), gd)\n",
    "\n",
    "print (x_train)\n",
    "#X_plt = X[:, [0,1]]\n",
    "\n",
    "#plot_decision_regions(X_plt, y, clf=lr)\n",
    "#plt.title('Softmax Regression - Gradient Descent')\n",
    "#plt.show()\n",
    "\n",
    "plt.plot(range(len(lr2.cost_)), lr2.cost_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_target_test[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 2 Class Labels: [0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr2.predict(one_hot_cols_test.values)\n",
    "print('Last 2 Class Labels: %s' % y_pred[-100:])\n",
    "len(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Validation:\n",
    "    def cross_validate(self, data, k, model, gradient_obj, test_cols): \n",
    "        \n",
    "        train_col = None\n",
    "        \n",
    "        for c in test_cols:\n",
    "            if c in data:\n",
    "                train_col = c\n",
    "                break\n",
    "        \n",
    "        shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "            \n",
    "        folds = np.array_split(shuffled_data, k)\n",
    "        \n",
    "        error_sum = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            folds_to_train = folds.copy()\n",
    "            fold_to_test = folds_to_train[i]\n",
    "            del folds_to_train[i]\n",
    "            folds_to_train = pd.concat(folds_to_train, sort=False)\n",
    "            \n",
    "            x_train = folds_to_train.loc[:,folds_to_train.columns != train_col]\n",
    "            y_train = folds_to_train.loc[:,folds_to_train.columns == train_col]\n",
    "            \n",
    "            x_test = fold_to_test.loc[:,fold_to_test.columns != train_col]\n",
    "            y_test = fold_to_test.loc[:,fold_to_test.columns == train_col]\n",
    "            \n",
    "            model.fit(x_train, y_train.values.ravel(), gradient_obj)\n",
    "            predictions = model.predict(x_test)\n",
    "            error_sum += (1-np.mean(np.array_equal(predictions, y_test))) #change to correct error ! ! ! !\n",
    "            \n",
    "        return error_sum / k\n",
    "\n",
    "cross = Cross_Validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "1           0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "2           0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "3           0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "4           0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1433        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1434        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "1435        0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "1436        0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        6.0        0.0   \n",
      "1           0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
      "2           3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "3           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1432        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1433        2.0        0.0        0.0       11.0  ...        0.0        0.0   \n",
      "1434        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1435        4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1436        0.0        0.0        0.0        4.0  ...        0.0        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0           0.0        0.0        7.0       15.0       16.0       16.0   \n",
      "1           2.0       13.0       16.0       16.0       16.0        2.0   \n",
      "2           0.0       15.0       13.0        7.0        0.0        0.0   \n",
      "3           0.0        0.0       11.0        9.0        0.0        0.0   \n",
      "4           0.0        0.0       12.0       12.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        1.0        9.0       12.0       13.0        9.0        0.0   \n",
      "1433        0.0       12.0       16.0       15.0        9.0        1.0   \n",
      "1434        0.0        9.0       13.0        0.0        0.0        0.0   \n",
      "1435        0.0        6.0       16.0        4.0        0.0        0.0   \n",
      "1436        0.0        5.0       16.0       16.0       11.0        0.0   \n",
      "\n",
      "      pixel_7_7  target  \n",
      "0           6.0       6  \n",
      "1           0.0       5  \n",
      "2           0.0       3  \n",
      "3           0.0       4  \n",
      "4           0.0       4  \n",
      "...         ...     ...  \n",
      "1432        0.0       3  \n",
      "1433        0.0       3  \n",
      "1434        0.0       7  \n",
      "1435        0.0       7  \n",
      "1436        0.0       8  \n",
      "\n",
      "[1437 rows x 65 columns]\n",
      "     duration  credit_amount  installment_commitment  residence_since   age  \\\n",
      "0        36.0         2862.0                     4.0              3.0  30.0   \n",
      "1        24.0         3123.0                     4.0              1.0  27.0   \n",
      "2        60.0         7408.0                     4.0              2.0  24.0   \n",
      "3        15.0         1264.0                     2.0              2.0  25.0   \n",
      "4         6.0         1554.0                     1.0              2.0  24.0   \n",
      "..        ...            ...                     ...              ...   ...   \n",
      "795      12.0         1082.0                     4.0              4.0  48.0   \n",
      "796      27.0         3915.0                     4.0              2.0  36.0   \n",
      "797       9.0         3832.0                     1.0              4.0  64.0   \n",
      "798      18.0         1928.0                     2.0              2.0  31.0   \n",
      "799      36.0         9857.0                     1.0              3.0  31.0   \n",
      "\n",
      "     existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0                 1.0             1.0                0        4   \n",
      "1                 1.0             1.0                1        4   \n",
      "2                 1.0             1.0                0        4   \n",
      "3                 1.0             1.0                0        4   \n",
      "4                 2.0             1.0                3        6   \n",
      "..                ...             ...              ...      ...   \n",
      "795               2.0             1.0                1        4   \n",
      "796               1.0             2.0                0        0   \n",
      "797               1.0             1.0                3        2   \n",
      "798               2.0             1.0                0        3   \n",
      "799               2.0             2.0                0        0   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 2  ...           3                3              2   \n",
      "1                 3  ...           2                0              2   \n",
      "2                 3  ...           2                0              2   \n",
      "3                 0  ...           0                2              2   \n",
      "4                 1  ...           1                0              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "795               4  ...           0                3              2   \n",
      "796               3  ...           0                3              2   \n",
      "797               3  ...           3                3              2   \n",
      "798               1  ...           2                3              2   \n",
      "799               2  ...           1                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     2                    1        0    1              0   \n",
      "1                     1                    1        1    1              0   \n",
      "2                     1                    1        1    0              0   \n",
      "3                     1                    1        2    1              0   \n",
      "4                     0                    1        2    1              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "795                   0                    0        1    1              0   \n",
      "796                   0                    1        1    1              1   \n",
      "797                   3                    1        1    3              0   \n",
      "798                   3                    1        1    3              0   \n",
      "799                   1                    1        1    3              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 1      0  \n",
      "2                 1      0  \n",
      "3                 1      0  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "795               1      0  \n",
      "796               1      0  \n",
      "797               1      1  \n",
      "798               1      0  \n",
      "799               1      1  \n",
      "\n",
      "[800 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# set up grid testing\n",
    "\n",
    "    \n",
    "param_grid = [\n",
    "  {'eta': np.arange(0.00001, 0.0001, 0.00005), 'l2': np.arange(0,0.1,0.1), 'epochs': [250], 'minibatches': np.arange(1,11, 10),'random_seed':[0],\n",
    "  'alphaa': np.arange(0.001, 0.011, 0.01), 'beta1': np.arange(0.9, 0.99, 0.09), 'max_iterations': [1e4], 'max_no_change': np.arange(10,20,10), \n",
    "  'adaptive': [False], 'beta2': np.arange(0.99, 0.999, 0.009), 'epsilon': np.arange(1e-9, 1e-8, 9e-9), 'minibatch_size': np.arange(1,10, 9),\n",
    "  'regularize': [0,1,2], 'lambdaa': np.arange(0.01, 0.1, 0.09)}\n",
    "]\n",
    "\n",
    "\n",
    "#merge train and train targets, send to cross validation for each grid\n",
    "print (digits_final)\n",
    "print (credit_final)\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, eta=0.01, l2=0, epochs=50, minibatches=1, random_seed=0, alphaa=0.001, beta1=0.9, max_iterations=1e4, max_no_change=20,\n",
    "                 adaptive=False, beta2=0.999, epsilon=1e-8, minibatch_size=0, regularize=0, lambdaa=0.1):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        self.l2 = l2\n",
    "        self.minibatches = minibatches\n",
    "        self.random_seed = random_seed\n",
    "        self.alphaa = alphaa\n",
    "        self.beta1 = beta1\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_no_change = max_no_change\n",
    "        self.adaptive = adaptive\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.regularize = regularize\n",
    "        self.lambdaa = lambdaa\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        params = {'eta': self.eta, 'l2': self.l2, 'epochs': self.epochs, 'minibatches': self.minibatches,'random_seed':self.random_seed,\n",
    "                  'alphaa': self.alphaa, 'beta1': self.beta1, 'max_iterations': self.max_iterations, 'max_no_change': self.max_no_change, \n",
    "                  'adaptive': self.adaptive, 'beta2':self.beta2, 'epsilon': self.epsilon, 'minibatch_size': self.minibatch_size,\n",
    "                  'regularize': self.regularize, 'lambdaa': self.lambdaa}\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self,X):\n",
    "        self.lr = SoftmaxRegression(eta=self.eta, epochs=self.epochs, minibatches=self.minibatches, random_seed=self.random_seed)\n",
    "        self.gd = GradientDescent(alphaa=self.alphaa, max_iterations=self.max_iterations, max_no_change=self.max_no_change,\n",
    "                                  adaptive=self.adaptive, beta2=self.beta2, epsilon=self.epsilon, regularize=self.regularize,\n",
    "                                  lambdaa=self.lambdaa, minibatch_size=self.minibatch_size)\n",
    "        self.cost = cross.cross_validate(X, 5, self.lr, self.gd, ['target', 'class'])\n",
    "        \n",
    "    \n",
    "def test_scorer(estimator):\n",
    "    return estimator.error\n",
    "\n",
    "# def tester_scorer_credit(estimator, X):\n",
    "#     error = cross.cross_validate(X, 5, estimator.lr, estimator.gd, 'class')\n",
    "#     return error\n",
    "    \n",
    "cv = [(slice(None), slice(None))] # dont use grid search cross validation, want to use our own\n",
    "gs = GridSearchCV(estimator=Tester(), param_grid=param_grid, \n",
    "                  scoring=test_scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "gs.fit(digits_final)\n",
    "#get best hyper parameters, then run test data using them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
