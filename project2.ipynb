{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "1109        0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "940         0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "192         0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "260         0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "1148        0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "835         0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1216        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1653        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "559         0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "684         0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
      "1109        0.0        0.0        0.0        0.0  ...       15.0        6.0   \n",
      "940         0.0        0.0        0.0        1.0  ...        8.0        0.0   \n",
      "192         3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "260         0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1148        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "835         0.0        0.0        0.0        2.0  ...        1.0        0.0   \n",
      "1216        2.0        0.0        0.0       11.0  ...        7.0        0.0   \n",
      "1653        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "559         4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "684         0.0        0.0        0.0        4.0  ...        1.0        0.0   \n",
      "\n",
      "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
      "1109        0.0        0.0        0.0        7.0       15.0       16.0   \n",
      "940         0.0        2.0       13.0       16.0       16.0       16.0   \n",
      "192         0.0        0.0       15.0       13.0        7.0        0.0   \n",
      "260         0.0        0.0        0.0       11.0        9.0        0.0   \n",
      "1148        0.0        0.0        0.0       12.0       12.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "835         0.0        1.0        9.0       12.0       13.0        9.0   \n",
      "1216        0.0        0.0       12.0       16.0       15.0        9.0   \n",
      "1653        0.0        0.0        9.0       13.0        0.0        0.0   \n",
      "559         0.0        0.0        6.0       16.0        4.0        0.0   \n",
      "684         0.0        0.0        5.0       16.0       16.0       11.0   \n",
      "\n",
      "      pixel_7_6  pixel_7_7  \n",
      "1109       16.0        6.0  \n",
      "940         2.0        0.0  \n",
      "192         0.0        0.0  \n",
      "260         0.0        0.0  \n",
      "1148        0.0        0.0  \n",
      "...         ...        ...  \n",
      "835         0.0        0.0  \n",
      "1216        1.0        0.0  \n",
      "1653        0.0        0.0  \n",
      "559         0.0        0.0  \n",
      "684         0.0        0.0  \n",
      "\n",
      "[1437 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "d = datasets.load_digits(as_frame=True)\n",
    "digits = d['data']\n",
    "digits_target = d['target']\n",
    "\n",
    "c = datasets.fetch_openml(name='credit-g', as_frame=True)\n",
    "credit = c['data']\n",
    "credit_target = c['target']\n",
    "\n",
    "digits, digits_test, digits_target, digits_target_test = train_test_split(digits, digits_target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "credit, credit_test, credit_target, credit_target_test = train_test_split(credit, credit_target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print (digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "1           0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "2           0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "3           0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "4           0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1433        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1434        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "1435        0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "1436        0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        6.0        0.0   \n",
      "1           0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
      "2           3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "3           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1432        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1433        2.0        0.0        0.0       11.0  ...        0.0        0.0   \n",
      "1434        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1435        4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1436        0.0        0.0        0.0        4.0  ...        0.0        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0           0.0        0.0        7.0       15.0       16.0       16.0   \n",
      "1           2.0       13.0       16.0       16.0       16.0        2.0   \n",
      "2           0.0       15.0       13.0        7.0        0.0        0.0   \n",
      "3           0.0        0.0       11.0        9.0        0.0        0.0   \n",
      "4           0.0        0.0       12.0       12.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        1.0        9.0       12.0       13.0        9.0        0.0   \n",
      "1433        0.0       12.0       16.0       15.0        9.0        1.0   \n",
      "1434        0.0        9.0       13.0        0.0        0.0        0.0   \n",
      "1435        0.0        6.0       16.0        4.0        0.0        0.0   \n",
      "1436        0.0        5.0       16.0       16.0       11.0        0.0   \n",
      "\n",
      "      pixel_7_7  target  \n",
      "0           6.0       6  \n",
      "1           0.0       5  \n",
      "2           0.0       3  \n",
      "3           0.0       4  \n",
      "4           0.0       4  \n",
      "...         ...     ...  \n",
      "1432        0.0       3  \n",
      "1433        0.0       3  \n",
      "1434        0.0       7  \n",
      "1435        0.0       7  \n",
      "1436        0.0       8  \n",
      "\n",
      "[1437 rows x 65 columns]\n",
      "     pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0          0.0        0.0       11.0       16.0       15.0        3.0   \n",
      "1          0.0        1.0       15.0       14.0        2.0        0.0   \n",
      "2          0.0        2.0       13.0       16.0       10.0        0.0   \n",
      "3          0.0        0.0        9.0        7.0        0.0        0.0   \n",
      "4          0.0        0.0        3.0       13.0        6.0        0.0   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "355        0.0        0.0        3.0        8.0       11.0       13.0   \n",
      "356        0.0        0.0        0.0        9.0       11.0        0.0   \n",
      "357        0.0        1.0        9.0       16.0       16.0       12.0   \n",
      "358        0.0        0.0        0.0        3.0       14.0       13.0   \n",
      "359        0.0        0.0        0.0        9.0       13.0       10.0   \n",
      "\n",
      "     pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0          0.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "1          0.0        0.0        0.0        6.0  ...        0.0        0.0   \n",
      "2          0.0        0.0        0.0       12.0  ...        0.0        0.0   \n",
      "3          0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "4          0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "355       14.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "356        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "357        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "358        3.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "359        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "\n",
      "     pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0          0.0       13.0       13.0        8.0       13.0       16.0   \n",
      "1          1.0       15.0       16.0       12.0        1.0        0.0   \n",
      "2          1.0       13.0       16.0       16.0       16.0       16.0   \n",
      "3          0.0        7.0       14.0       16.0       12.0        1.0   \n",
      "4          0.0        3.0       13.0       15.0        8.0        0.0   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "355        0.0        2.0       12.0       13.0        2.0        0.0   \n",
      "356        0.0        0.0       11.0        7.0        0.0        0.0   \n",
      "357        0.0       10.0       16.0       11.0        4.0        0.0   \n",
      "358        0.0        0.0        3.0       13.0       15.0        2.0   \n",
      "359        0.0        0.0       10.0       16.0       12.0        0.0   \n",
      "\n",
      "     pixel_7_7  target  \n",
      "0          8.0       2  \n",
      "1          0.0       8  \n",
      "2          3.0       2  \n",
      "3          0.0       6  \n",
      "4          0.0       6  \n",
      "..         ...     ...  \n",
      "355        0.0       5  \n",
      "356        0.0       4  \n",
      "357        0.0       3  \n",
      "358        0.0       8  \n",
      "359        0.0       8  \n",
      "\n",
      "[360 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# no preprocessing needed \n",
    "\n",
    "digits_final = pd.concat([digits, digits_target], axis=1)\n",
    "digits_final.reset_index(drop=True, inplace=True)\n",
    "print (digits_final)\n",
    "\n",
    "digits_test_final = pd.concat([digits_test, digits_target_test], axis=1)\n",
    "digits_test_final.reset_index(drop=True, inplace=True)\n",
    "print (digits_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0    0.500000       0.155341                    1.00             0.75   \n",
      "1    0.333333       0.169507                    1.00             0.25   \n",
      "2    0.833333       0.402084                    1.00             0.50   \n",
      "3    0.208333       0.068606                    0.50             0.50   \n",
      "4    0.083333       0.084347                    0.25             0.50   \n",
      "..        ...            ...                     ...              ...   \n",
      "795  0.166667       0.058728                    1.00             1.00   \n",
      "796  0.375000       0.212495                    1.00             0.50   \n",
      "797  0.125000       0.207990                    0.25             1.00   \n",
      "798  0.250000       0.104646                    0.50             0.50   \n",
      "799  0.500000       0.535009                    0.25             0.75   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.400000              0.25             0.5                0        4   \n",
      "1    0.360000              0.25             0.5                1        4   \n",
      "2    0.320000              0.25             0.5                0        4   \n",
      "3    0.333333              0.25             0.5                0        4   \n",
      "4    0.320000              0.50             0.5                3        6   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "795  0.640000              0.50             0.5                1        4   \n",
      "796  0.480000              0.25             1.0                0        0   \n",
      "797  0.853333              0.25             0.5                3        2   \n",
      "798  0.413333              0.50             0.5                0        3   \n",
      "799  0.413333              0.50             1.0                0        0   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 2  ...           3                3              2   \n",
      "1                 3  ...           2                0              2   \n",
      "2                 3  ...           2                0              2   \n",
      "3                 0  ...           0                2              2   \n",
      "4                 1  ...           1                0              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "795               4  ...           0                3              2   \n",
      "796               3  ...           0                3              2   \n",
      "797               3  ...           3                3              2   \n",
      "798               1  ...           2                3              2   \n",
      "799               2  ...           1                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     2                    1        0    1              0   \n",
      "1                     1                    1        1    1              0   \n",
      "2                     1                    1        1    0              0   \n",
      "3                     1                    1        2    1              0   \n",
      "4                     0                    1        2    1              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "795                   0                    0        1    1              0   \n",
      "796                   0                    1        1    1              1   \n",
      "797                   3                    1        1    3              0   \n",
      "798                   3                    1        1    3              0   \n",
      "799                   1                    1        1    3              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 1      0  \n",
      "2                 1      0  \n",
      "3                 1      0  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "795               1      0  \n",
      "796               1      0  \n",
      "797               1      1  \n",
      "798               1      0  \n",
      "799               1      1  \n",
      "\n",
      "[800 rows x 21 columns]\n",
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0        0.60       0.272003                    1.00             0.75   \n",
      "1        0.15       0.245757                    0.25             0.50   \n",
      "2        0.30       0.172793                    0.75             1.00   \n",
      "3        0.20       0.137066                    1.00             0.25   \n",
      "4        1.00       0.712195                    0.50             1.00   \n",
      "..        ...            ...                     ...              ...   \n",
      "195      0.30       0.099828                    0.75             0.25   \n",
      "196      0.20       0.084370                    1.00             0.50   \n",
      "197      0.10       0.064033                    0.25             0.75   \n",
      "198      0.60       0.555548                    0.50             1.00   \n",
      "199      0.10       0.092477                    0.50             1.00   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.461538              0.25             0.5                1        3   \n",
      "1    0.400000              0.25             1.0                3        4   \n",
      "2    0.661538              0.25             0.5                3        3   \n",
      "3    0.415385              0.25             0.5                0        4   \n",
      "4    0.646154              0.25             0.5                3        4   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "195  0.400000              0.25             0.5                3        6   \n",
      "196  0.369231              0.25             0.5                1        4   \n",
      "197  0.600000              0.50             0.5                0        8   \n",
      "198  0.646154              1.00             0.5                0        4   \n",
      "199  0.646154              0.25             1.0                3        6   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 3  ...           4                3              2   \n",
      "1                 3  ...           0                3              1   \n",
      "2                 3  ...           0                3              2   \n",
      "3                 1  ...           2                3              2   \n",
      "4                 3  ...           3                3              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "195               3  ...           2                0              2   \n",
      "196               3  ...           0                0              2   \n",
      "197               1  ...           1                0              2   \n",
      "198               2  ...           3                3              2   \n",
      "199               3  ...           3                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     1                    1        1    0              1   \n",
      "1                     3                    1        2    1              0   \n",
      "2                     3                    1        1    1              1   \n",
      "3                     0                    1        1    1              0   \n",
      "4                     1                    1        1    0              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "195                   3                    1        1    1              0   \n",
      "196                   3                    1        1    3              0   \n",
      "197                   1                    1        1    3              0   \n",
      "198                   0                    1        1    0              1   \n",
      "199                   2                    0        0    1              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 0      1  \n",
      "2                 1      1  \n",
      "3                 1      1  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "195               1      1  \n",
      "196               1      0  \n",
      "197               1      1  \n",
      "198               1      0  \n",
      "199               1      1  \n",
      "\n",
      "[200 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#everything good with data except categorical to one hot needed \n",
    "credit_cat = ['checking_status', 'purpose', 'credit_history', 'savings_status', 'employment', 'personal_status', 'other_parties',\n",
    "             'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker', 'class']\n",
    "\n",
    "def extract_columns (df, cols):\n",
    "    return df.loc[:, cols]\n",
    "\n",
    "def get_onehot (df, cat_feat):\n",
    "    categories = extract_columns(df, cat_feat)\n",
    "    le = LabelEncoder()\n",
    "    return categories.apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "merged_credit = pd.concat([credit, credit_target], axis=1)\n",
    "merged_credit.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merged_credit_test = pd.concat([credit_test, credit_target_test], axis=1)\n",
    "merged_credit_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "one_hot_cols = get_onehot(merged_credit, credit_cat)\n",
    "credit_no_cat = merged_credit.drop(credit_cat, axis = 1) \n",
    "credit_no_cat = credit_no_cat.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x))) #normalize continuous data\n",
    "credit_final = pd.concat([credit_no_cat, one_hot_cols], axis=1)\n",
    "\n",
    "\n",
    "one_hot_cols_test = get_onehot(merged_credit_test, credit_cat)\n",
    "credit_test_no_cat = merged_credit_test.drop(credit_cat, axis=1)\n",
    "credit_test_no_cat = credit_test_no_cat.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "credit_test_final = pd.concat([credit_test_no_cat, one_hot_cols_test], axis=1)\n",
    "\n",
    "#le = LabelEncoder()\n",
    "\n",
    "#credit_target = le.fit_transform(credit_target)\n",
    "#credit_target_test = le.fit_transform(credit_target_test)\n",
    "\n",
    "print (credit_final)\n",
    "print (credit_test_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optimizer class implementing minibatch gradient descent for softmax regression. Can utilize either\n",
    "    gradient descent with momentum, or Adaptive Momentum Estimation (Adam), with optional L1 or L2\n",
    "    regularization.\n",
    "\"\"\"\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
    "\n",
    "\n",
    "# Shuffles the (x,y) instances, and outputs a list of minibatch_size sized (x,y) tuples\n",
    "def minibatch(x, y, minibatch_size):\n",
    "    x, y = shuffle(x, y)\n",
    "    minibatches = []\n",
    "    if not minibatch_size:\n",
    "        minibatches.append((x, y))\n",
    "    else:\n",
    "        for i in range(0, x.shape[0], minibatch_size):\n",
    "            x_mini = x[i:i+minibatch_size]\n",
    "            y_mini = y[i:i+minibatch_size]\n",
    "            minibatches.append((x_mini, y_mini))\n",
    "    return minibatches\n",
    "\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(y, yh):\n",
    "    pred = np.argmax(yh, axis=1)\n",
    "    y_int = y.astype(np.int64)\n",
    "    return np.mean(np.equal(pred, y_int))\n",
    "\n",
    "\n",
    "# Returns the index of the maximum value in a list\n",
    "def argmax(lst):\n",
    "    return lst.index(max(lst))\n",
    "\n",
    "\n",
    "class GradientDescent:\n",
    "\n",
    "    \"\"\"\n",
    "    Class fields:\n",
    "       alphaa - learning rate of the optimizer\n",
    "       beta1 - momentum hyperparameter\n",
    "       max_iterations - gradient descent termination condition: maximum times iterated\n",
    "       max_no_change - gradient descent termination condition: maximum number of iterations\n",
    "                         without the validation error decreasing\n",
    "       minibatch_size - size of the minibatch to use (default value of 0 indicates use full batch)\n",
    "       cost_fn - optional cost function, if included optimizer will calculate and store the\n",
    "                    training and validation cost at each iteration\n",
    "       adaptive - if true, optimizer uses Adam (Adaptive Moment Estimation) rather than gradient\n",
    "                    descent with momentum\n",
    "       beta2 - 2nd hyperparameter for Adam (if using)\n",
    "       epsilon - 3rd hyperparameter for Adam (if using), just to avoid numerical issues\n",
    "       regularize - determines regularization used (if any): 0 indicates no regularization, 1 or 2\n",
    "                      indicate L1 or L2 regularization respectively\n",
    "       lambdaa - regularization coefficient if used\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(self, alphaa=0.01, beta1=0.9, max_iterations=1e4, max_no_change=20, minibatch_size=0,\n",
    "                 cost_fn=None, adaptive=False, beta2=0.999, epsilon=1e-8, regularize=0, lambdaa=0.1):\n",
    "\n",
    "        self.alphaa = alphaa\n",
    "        self.beta1 = beta1\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_no_change = max_no_change\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.cost_fn = cost_fn\n",
    "\n",
    "        self.adaptive = adaptive\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.regularize = regularize\n",
    "        self.lambdaa = lambdaa\n",
    "\n",
    "        self.accuracy_tr = []\n",
    "        self.accuracy_val = []\n",
    "        self.weight_history = []\n",
    "        if self.cost_fn:\n",
    "            self.cost_tr = []\n",
    "            self.cost_val = []\n",
    "\n",
    "    # Run method - delegates work to one of 2 helper methods, dependent on if Adam is being used or not\n",
    "    def run(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        if self.adaptive:\n",
    "            return self.adam(x_tr, y_tr, x_val, y_val, w)\n",
    "        else:\n",
    "            return self.momentum(x_tr, y_tr, x_val, y_val, w)\n",
    "\n",
    "    # Gradient Descent with Momentum\n",
    "    def momentum(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        t = 1\n",
    "        i = 0\n",
    "        delta_w = 0\n",
    "\n",
    "        self.accuracy_tr.append(accuracy(y_tr, softmax(np.dot(x_tr, w))))\n",
    "        self.accuracy_val.append(accuracy(y_val, softmax(np.dot(x_val, w))))\n",
    "\n",
    "        while i < self.max_no_change and t < self.max_iterations:\n",
    "            for (x_mini, y_mini) in minibatch(x_tr, y_tr, self.minibatch_size):\n",
    "                grad = self.gradient(x_mini, y_mini, w)\n",
    "                delta_w = (self.beta1 * delta_w) + ((1 - self.beta1) * grad)\n",
    "                w -= self.alphaa * delta_w\n",
    "\n",
    "            self.weight_history.append(w)\n",
    "            tr_pred = softmax(np.dot(x_tr, w))\n",
    "            pred = softmax(np.dot(x_val, w))\n",
    "            self.accuracy_tr.append(accuracy(y_tr, tr_pred))\n",
    "            self.accuracy_val.append(accuracy(y_val, pred))\n",
    "            if self.cost_fn:\n",
    "                self.cost_tr.append(self.cost_fn(y_tr, tr_pred))\n",
    "                self.cost_val.append(self.cost_fn(y_val, pred))\n",
    "\n",
    "            if not self.accuracy_val[-1] < self.accuracy_val[-2]:\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "            t += 1\n",
    "\n",
    "        return self.weight_history[argmax(self.accuracy_val)]\n",
    "\n",
    "    # Adaptive Moment Estimation\n",
    "    def adam(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        t = 1\n",
    "        i = 0\n",
    "        m = 0\n",
    "        s = 0\n",
    "\n",
    "        self.accuracy_tr.append(accuracy(y_tr, softmax(np.dot(x_tr, w))))\n",
    "        self.accuracy_val.append(accuracy(y_val, softmax(np.dot(x_val, w))))\n",
    "\n",
    "        while i < self.max_no_change and t < self.max_iterations:\n",
    "            for (x_mini, y_mini) in minibatch(x_tr, y_tr, self.minibatch_size):\n",
    "                grad = self.gradient(x_mini, y_mini, w)\n",
    "                m = (self.beta1 * m) + ((1 - self.beta1) * grad)\n",
    "                s = (self.beta2 * s) + ((1 - self.beta2) * np.power(grad, 2))\n",
    "                mh = m / (1 - np.power(self.beta1, t))\n",
    "                sh = s / (1 - np.power(self.beta2, t))\n",
    "                w -= self.alphaa * mh * grad / (np.sqrt(sh) + self.epsilon)\n",
    "\n",
    "            self.weight_history.append(w)\n",
    "            tr_pred = softmax(np.dot(x_tr, w))\n",
    "            pred = softmax(np.dot(x_val, w))\n",
    "            self.accuracy_tr.append(accuracy(y_tr, tr_pred))\n",
    "            self.accuracy_val.append(accuracy(y_val, pred))\n",
    "            if self.cost_fn:\n",
    "                self.cost_tr.append(self.cost_fn(y_tr, tr_pred))\n",
    "                self.cost_val.append(self.cost_fn(y_val, pred))\n",
    "\n",
    "            if not self.accuracy_val[-1] < self.accuracy_val[-2]:\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "            t += 1\n",
    "\n",
    "        return self.weight_history[argmax(self.accuracy_val)]\n",
    "\n",
    "    # Helper method to calculate gradient (and add regularization penalty if any)\n",
    "    def gradient(self, x, y, w):\n",
    "        n, d = x.shape\n",
    "        yh = softmax(np.dot(x, w))\n",
    "\n",
    "        grad = np.dot(x.T, yh - y) / n\n",
    "        if self.regularize == 1:\n",
    "            grad[1:] += self.lambdaa * np.sign(w[1:])\n",
    "        elif self.regularize == 2:\n",
    "            grad[1:] += self.lambdaa * w[1:]\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from .._base import _BaseClassifier\n",
    "#from .._base import _BaseMultiClass\n",
    "\n",
    "\n",
    "class SoftmaxRegression(object):\n",
    "\n",
    "    \"\"\"Softmax regression classifier.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, max_iters=50,\n",
    "                 l2=0.0,\n",
    "                 minibatches=1,\n",
    "                 n_classes=None,\n",
    "                 random_seed=None):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.l2 = l2\n",
    "        self.minibatches = minibatches\n",
    "        self.n_classes = n_classes\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "\n",
    "    def fit(self, X, y, gd):\n",
    "        \n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "  \n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = np.max(y) + 1\n",
    "        self._n_features = X.shape[1]\n",
    "\n",
    "\n",
    "        \"\"\"Initialize weight coefficients.\"\"\"\n",
    "        np.random.seed(self.random_seed)\n",
    "        self.w_ = np.random.normal(loc=0.0, scale=0.01, size=(self._n_features, self.n_classes)).astype('float64')\n",
    "        self.cost_ = []\n",
    "\n",
    "        y_enc = self._one_hot(y=y, n_labels=self.n_classes, dtype=np.float)\n",
    "     \n",
    "        for i in range(self.max_iters):\n",
    "           \n",
    "            \n",
    "            #GRADIENT DESCENT line below (make sure to split X, y into training and validation sets)\n",
    "            \n",
    "            self._w = gd.run(X,y_enc,X,y_enc,self.w_)\n",
    "            \n",
    "            #COMMENT THE FOR LOOP BELOW\n",
    "\n",
    "            \"\"\" \n",
    "            for idx in self._yield_minibatches_idx(\n",
    "                    n_batches=self.minibatches,\n",
    "                    data_ary=y,\n",
    "                    shuffle=True):\n",
    "                # givens:\n",
    "                # w_ -> n_feat x n_classes\n",
    "                # b_  -> n_classes\n",
    "                \n",
    "                # net_input, softmax and diff -> n_samples x n_classes:\n",
    "                net = X[idx].dot(self.w_) #net_input\n",
    "                softm = self.softmax(net) \n",
    "                diff = softm - y_enc[idx]\n",
    "                mse = np.mean(diff, axis=0)\n",
    "\n",
    "                # gradient -> n_features x n_classes\n",
    "                grad = np.dot(X[idx].T, diff)\n",
    "                \n",
    "                # update in opp. direction of the cost gradient\n",
    "                self.w_ -= (self.eta * grad +\n",
    "                            self.eta * self.l2 * self.w_)  \n",
    "            \n",
    "            \"\"\"  \n",
    "            # compute cost of the whole epoch\n",
    "            net = X.dot(self.w_)\n",
    "            softm = self.softmax(net)\n",
    "            cross_ent = self.cross_entropy(output=softm, y_target=y_enc)\n",
    "            cost = self.cost(cross_ent)\n",
    "            self.cost_.append(cost)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        #Predict targets from X.\n",
    "\n",
    "        net = X.dot(self.w_)\n",
    "        probas = self.softmax(net)\n",
    "        return probas.argmax(axis=1)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
    "\n",
    "\n",
    "    def cross_entropy(self, output, y_target):\n",
    "        return - np.sum(np.log(output) * (y_target), axis=1)\n",
    "\n",
    "    def cost(self, cross_entropy):\n",
    "        L2_term = self.l2 * np.sum(self.w_ ** 2)\n",
    "        cross_entropy = cross_entropy + L2_term\n",
    "        return 0.5 * np.mean(cross_entropy)\n",
    "\n",
    "\n",
    "    def _one_hot(self, y, n_labels, dtype):\n",
    "        mat = np.zeros((len(y), n_labels))\n",
    "        for i, val in enumerate(y):\n",
    "            mat[i, val] = 1\n",
    "        return mat.astype(dtype)    \n",
    "    \n",
    "    def _yield_minibatches_idx(self, n_batches, data_ary, shuffle=True):\n",
    "            indices = np.arange(data_ary.shape[0])\n",
    "\n",
    "            if shuffle:\n",
    "                indices = np.random.permutation(indices)\n",
    "            if n_batches > 1:\n",
    "                remainder = data_ary.shape[0] % n_batches\n",
    "\n",
    "                if remainder:\n",
    "                    minis = np.array_split(indices[:-remainder], n_batches)\n",
    "                    minis[-1] = np.concatenate((minis[-1],\n",
    "                                                indices[-remainder:]),\n",
    "                                               axis=0)\n",
    "                else:\n",
    "                    minis = np.array_split(indices, n_batches)\n",
    "\n",
    "            else:\n",
    "                minis = (indices,)\n",
    "\n",
    "            for idx_batch in minis:\n",
    "                yield idx_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1     2     3     4     5    6    7    8     9   ...    54   55  \\\n",
      "0     0.0  0.0   0.0   9.0  15.0   2.0  0.0  0.0  0.0   0.0  ...  15.0  6.0   \n",
      "1     0.0  3.0  12.0  12.0  14.0   4.0  0.0  0.0  0.0   1.0  ...   8.0  0.0   \n",
      "2     0.0  1.0  10.0  15.0  16.0  13.0  3.0  0.0  0.0   5.0  ...   0.0  0.0   \n",
      "3     0.0  0.0   0.0  12.0   4.0   0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
      "4     0.0  0.0   0.0   9.0  16.0   3.0  0.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
      "...   ...  ...   ...   ...   ...   ...  ...  ...  ...   ...  ...   ...  ...   \n",
      "1432  0.0  1.0   8.0  14.0  15.0   2.0  0.0  0.0  0.0   2.0  ...   1.0  0.0   \n",
      "1433  0.0  2.0   9.0  15.0  16.0  15.0  2.0  0.0  0.0  11.0  ...   7.0  0.0   \n",
      "1434  0.0  0.0   5.0  14.0  14.0   2.0  0.0  0.0  0.0   2.0  ...   0.0  0.0   \n",
      "1435  0.0  0.0   4.0  10.0  15.0  16.0  4.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
      "1436  0.0  0.0   6.0  14.0  13.0   4.0  0.0  0.0  0.0   4.0  ...   1.0  0.0   \n",
      "\n",
      "       56   57    58    59    60    61    62   63  \n",
      "0     0.0  0.0   0.0   7.0  15.0  16.0  16.0  6.0  \n",
      "1     0.0  2.0  13.0  16.0  16.0  16.0   2.0  0.0  \n",
      "2     0.0  0.0  15.0  13.0   7.0   0.0   0.0  0.0  \n",
      "3     0.0  0.0   0.0  11.0   9.0   0.0   0.0  0.0  \n",
      "4     0.0  0.0   0.0  12.0  12.0   0.0   0.0  0.0  \n",
      "...   ...  ...   ...   ...   ...   ...   ...  ...  \n",
      "1432  0.0  1.0   9.0  12.0  13.0   9.0   0.0  0.0  \n",
      "1433  0.0  0.0  12.0  16.0  15.0   9.0   1.0  0.0  \n",
      "1434  0.0  0.0   9.0  13.0   0.0   0.0   0.0  0.0  \n",
      "1435  0.0  0.0   6.0  16.0   4.0   0.0   0.0  0.0  \n",
      "1436  0.0  0.0   5.0  16.0  16.0  11.0   0.0  0.0  \n",
      "\n",
      "[1437 rows x 64 columns]\n",
      "       0      1       2       3       4       5       6    7    8       9   \\\n",
      "0     0.0  0.000  0.0000  0.5625  0.9375  0.1250  0.0000  0.0  0.0  0.0000   \n",
      "1     0.0  0.375  0.7500  0.7500  0.8750  0.2500  0.0000  0.0  0.0  0.0625   \n",
      "2     0.0  0.125  0.6250  0.9375  1.0000  0.8125  0.1875  0.0  0.0  0.3125   \n",
      "3     0.0  0.000  0.0000  0.7500  0.2500  0.0000  0.0000  0.0  0.0  0.0000   \n",
      "4     0.0  0.000  0.0000  0.5625  1.0000  0.1875  0.0000  0.0  0.0  0.0000   \n",
      "...   ...    ...     ...     ...     ...     ...     ...  ...  ...     ...   \n",
      "1432  0.0  0.125  0.5000  0.8750  0.9375  0.1250  0.0000  0.0  0.0  0.1250   \n",
      "1433  0.0  0.250  0.5625  0.9375  1.0000  0.9375  0.1250  0.0  0.0  0.6875   \n",
      "1434  0.0  0.000  0.3125  0.8750  0.8750  0.1250  0.0000  0.0  0.0  0.1250   \n",
      "1435  0.0  0.000  0.2500  0.6250  0.9375  1.0000  0.2500  0.0  0.0  0.0000   \n",
      "1436  0.0  0.000  0.3750  0.8750  0.8125  0.2500  0.0000  0.0  0.0  0.2500   \n",
      "\n",
      "      ...      54        55   56        57      58      59      60      61  \\\n",
      "0     ...  0.9375  0.461538  0.0  0.000000  0.0000  0.4375  0.9375  1.0000   \n",
      "1     ...  0.5000  0.000000  0.0  0.222222  0.8125  1.0000  1.0000  1.0000   \n",
      "2     ...  0.0000  0.000000  0.0  0.000000  0.9375  0.8125  0.4375  0.0000   \n",
      "3     ...  0.0000  0.000000  0.0  0.000000  0.0000  0.6875  0.5625  0.0000   \n",
      "4     ...  0.0000  0.000000  0.0  0.000000  0.0000  0.7500  0.7500  0.0000   \n",
      "...   ...     ...       ...  ...       ...     ...     ...     ...     ...   \n",
      "1432  ...  0.0625  0.000000  0.0  0.111111  0.5625  0.7500  0.8125  0.5625   \n",
      "1433  ...  0.4375  0.000000  0.0  0.000000  0.7500  1.0000  0.9375  0.5625   \n",
      "1434  ...  0.0000  0.000000  0.0  0.000000  0.5625  0.8125  0.0000  0.0000   \n",
      "1435  ...  0.0000  0.000000  0.0  0.000000  0.3750  1.0000  0.2500  0.0000   \n",
      "1436  ...  0.0625  0.000000  0.0  0.000000  0.3125  1.0000  1.0000  0.6875   \n",
      "\n",
      "          62     63  \n",
      "0     1.0000  0.375  \n",
      "1     0.1250  0.000  \n",
      "2     0.0000  0.000  \n",
      "3     0.0000  0.000  \n",
      "4     0.0000  0.000  \n",
      "...      ...    ...  \n",
      "1432  0.0000  0.000  \n",
      "1433  0.0625  0.000  \n",
      "1434  0.0000  0.000  \n",
      "1435  0.0000  0.000  \n",
      "1436  0.0000  0.000  \n",
      "\n",
      "[1437 rows x 64 columns]\n",
      "[6 5 3 ... 7 7 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading Data\n",
    "\n",
    "#X = one_hot_cols.values\n",
    "#y = credit_target.values\n",
    "\n",
    "X = digits.values\n",
    "y = digits_target.values\n",
    "\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "print (df)\n",
    "df = df.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "\n",
    "print (df)\n",
    "#standardize\n",
    "# X[:,0] = X[:,0] / np.amax(X[:,0])\n",
    "# X[:,1] = X[:,1] / np.amax(X[:,1])\n",
    "\n",
    "print (y)\n",
    "\n",
    "lr = SoftmaxRegression(learning_rate=0.00001, max_iters=250, minibatches=1, random_seed=0)\n",
    "gd = GradientDescent()\n",
    "lr.fit(df.to_numpy(), y, gd)\n",
    "\n",
    "# #X_plt = X[:, [0,1]]\n",
    "\n",
    "# #plot_decision_regions(X_plt, y, clf=lr)\n",
    "# #plt.title('Softmax Regression - Gradient Descent')\n",
    "# #plt.show()\n",
    "\n",
    "plt.plot(range(len(lr.cost_)), lr.cost_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5, 2, 8, 6, 6, 6, 6, 1, 0, 5, 8, 8, 7,\n",
       "       8, 4, 7, 5, 4, 9, 2, 9, 4, 7, 6, 8, 9, 4, 3, 1, 0, 1, 8, 6, 7, 7,\n",
       "       1, 0, 7, 6, 2, 1, 9, 6, 7, 9, 0, 0, 5, 1, 6, 3, 0, 2, 3, 4, 1, 9,\n",
       "       2, 6, 9, 1, 8, 3, 5, 1, 2, 8, 2, 2, 9, 7, 2, 3, 6, 0, 5, 3, 7, 5,\n",
       "       1, 2, 9, 9, 3, 1, 7, 7, 4, 8, 5, 8, 5, 5, 2, 5, 9, 0, 7, 1, 4, 7,\n",
       "       3, 4, 8, 9, 7, 9, 8, 2, 6, 5, 2, 5, 8, 4, 8, 7, 0, 6, 1, 5, 9, 9,\n",
       "       9, 5, 9, 9, 5, 7, 5, 6, 2, 8, 6, 9, 6, 1, 5, 1, 5, 9, 9, 1, 5, 3,\n",
       "       6, 1, 8, 9, 8, 7, 6, 7, 6, 5, 6, 0, 8, 8, 9, 8, 6, 1, 0, 4, 1, 6,\n",
       "       3, 8, 6, 7, 4, 5, 6, 3, 0, 3, 3, 3, 0, 7, 7, 5, 7, 8, 0, 7, 8, 9,\n",
       "       6, 4, 5, 0, 1, 4, 6, 4, 3, 3, 0, 9, 5, 9, 2, 1, 4, 2, 1, 6, 8, 9,\n",
       "       2, 4, 9, 3, 7, 6, 2, 3, 3, 1, 6, 9, 3, 6, 3, 2, 2, 0, 7, 6, 1, 1,\n",
       "       9, 7, 2, 7, 8, 5, 5, 7, 5, 2, 3, 7, 2, 7, 5, 5, 7, 0, 9, 1, 6, 5,\n",
       "       9, 7, 4, 3, 8, 0, 3, 6, 4, 6, 3, 2, 6, 8, 8, 8, 4, 6, 7, 5, 2, 4,\n",
       "       5, 3, 2, 4, 6, 9, 4, 5, 4, 3, 4, 6, 2, 9, 0, 1, 7, 2, 0, 9, 6, 0,\n",
       "       4, 2, 0, 7, 9, 8, 5, 4, 8, 2, 8, 4, 3, 7, 2, 6, 9, 1, 5, 1, 0, 8,\n",
       "       2, 1, 9, 5, 6, 8, 2, 7, 2, 1, 5, 1, 6, 4, 5, 0, 9, 4, 1, 1, 7, 0,\n",
       "       8, 9, 0, 5, 4, 3, 8, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_target_test.values[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 2 Class Labels: [2 8 2 6 6 7 1 9 8 5 2 8 6 6 6 6 1 0 5 8 8 7 8 4 7 5 4 9 2 9 4 7 6 8 9 4 3\n",
      " 1 0 1 8 6 7 7 9 0 7 6 2 1 9 6 7 9 0 0 9 1 6 3 0 2 3 4 1 9 7 6 9 1 8 3 5 1\n",
      " 2 1 2 2 9 7 2 3 6 0 5 3 7 5 1 2 9 9 3 1 7 7 4 8 5 8 5 5 2 5 9 0 7 1 4 7 3\n",
      " 4 8 9 7 7 8 0 1 9 2 5 8 4 1 7 0 6 1 5 9 9 9 5 9 9 5 7 5 6 2 8 6 9 6 1 5 1\n",
      " 5 9 9 1 5 3 6 1 8 9 7 7 6 7 6 5 6 0 8 8 9 3 6 1 0 7 1 6 3 8 6 7 4 9 6 3 0\n",
      " 3 3 3 0 7 7 5 7 8 0 7 8 9 6 4 5 0 1 4 6 4 3 3 0 9 5 9 3 9 4 7 1 6 8 9 2 4\n",
      " 9 3 7 6 2 3 3 1 6 9 3 6 3 3 2 0 7 6 1 1 3 7 2 7 1 5 5 7 5 2 2 7 2 7 5 5 7\n",
      " 0 9 1 6 5 9 7 4 3 8 0 3 6 4 6 3 2 6 8 8 8 4 6 7 5 2 4 5 3 2 4 6 9 4 5 4 3\n",
      " 4 6 2 9 0 6 7 2 0 9 6 0 4 2 0 7 5 8 5 7 8 2 8 4 3 7 2 6 5 9 5 1 0 8 2 5 9\n",
      " 5 6 8 2 7 2 1 5 1 6 4 5 0 9 4 1 1 7 0 8 9 0 5 4 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = lr.predict(digits_test.values)\n",
    "print('Last 2 Class Labels: %s' % y_pred[0:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.15534086 1.         ... 1.         0.         1.        ]\n",
      " [0.33333333 0.16950716 1.         ... 1.         0.         1.        ]\n",
      " [0.83333333 0.40208424 1.         ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.125      0.20798958 0.25       ... 3.         0.         1.        ]\n",
      " [0.25       0.10464611 0.5        ... 3.         0.         1.        ]\n",
      " [0.5        0.53500868 0.25       ... 3.         1.         1.        ]]\n",
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0    0.500000       0.155341                    1.00             0.75   \n",
      "1    0.333333       0.169507                    1.00             0.25   \n",
      "2    0.833333       0.402084                    1.00             0.50   \n",
      "3    0.208333       0.068606                    0.50             0.50   \n",
      "4    0.083333       0.084347                    0.25             0.50   \n",
      "..        ...            ...                     ...              ...   \n",
      "795  0.166667       0.058728                    1.00             1.00   \n",
      "796  0.375000       0.212495                    1.00             0.50   \n",
      "797  0.125000       0.207990                    0.25             1.00   \n",
      "798  0.250000       0.104646                    0.50             0.50   \n",
      "799  0.500000       0.535009                    0.25             0.75   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.400000              0.25             0.5                0        4   \n",
      "1    0.360000              0.25             0.5                1        4   \n",
      "2    0.320000              0.25             0.5                0        4   \n",
      "3    0.333333              0.25             0.5                0        4   \n",
      "4    0.320000              0.50             0.5                3        6   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "795  0.640000              0.50             0.5                1        4   \n",
      "796  0.480000              0.25             1.0                0        0   \n",
      "797  0.853333              0.25             0.5                3        2   \n",
      "798  0.413333              0.50             0.5                0        3   \n",
      "799  0.413333              0.50             1.0                0        0   \n",
      "\n",
      "     credit_history  savings_status  employment  personal_status  \\\n",
      "0                 2               0           3                3   \n",
      "1                 3               2           2                0   \n",
      "2                 3               0           2                0   \n",
      "3                 0               0           0                2   \n",
      "4                 1               2           1                0   \n",
      "..              ...             ...         ...              ...   \n",
      "795               4               2           0                3   \n",
      "796               3               2           0                3   \n",
      "797               3               4           3                3   \n",
      "798               1               2           2                3   \n",
      "799               2               0           1                3   \n",
      "\n",
      "     other_parties  property_magnitude  other_payment_plans  housing  job  \\\n",
      "0                2                   2                    1        0    1   \n",
      "1                2                   1                    1        1    1   \n",
      "2                2                   1                    1        1    0   \n",
      "3                2                   1                    1        2    1   \n",
      "4                2                   0                    1        2    1   \n",
      "..             ...                 ...                  ...      ...  ...   \n",
      "795              2                   0                    0        1    1   \n",
      "796              2                   0                    1        1    1   \n",
      "797              2                   3                    1        1    3   \n",
      "798              2                   3                    1        1    3   \n",
      "799              2                   1                    1        1    3   \n",
      "\n",
      "     own_telephone  foreign_worker  \n",
      "0                0               1  \n",
      "1                0               1  \n",
      "2                0               1  \n",
      "3                0               1  \n",
      "4                1               1  \n",
      "..             ...             ...  \n",
      "795              0               1  \n",
      "796              1               1  \n",
      "797              0               1  \n",
      "798              0               1  \n",
      "799              1               1  \n",
      "\n",
      "[800 rows x 20 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Loading Data\n",
    "\n",
    "x_train = credit_final.loc[:,credit_final.columns != \"class\"]\n",
    "y_train = credit_final.loc[:,credit_final.columns == \"class\"]\n",
    "\n",
    "print (x_train.to_numpy())\n",
    "\n",
    "# df = pd.DataFrame(x_train)\n",
    "# df = df.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "\n",
    "lr2 = SoftmaxRegression(learning_rate=0.00001, max_iters=250, minibatches=1, random_seed=0)\n",
    "gd = GradientDescent()\n",
    "lr2.fit(x_train.to_numpy(), y_train.values.ravel(), gd)\n",
    "\n",
    "print (x_train)\n",
    "#X_plt = X[:, [0,1]]\n",
    "\n",
    "#plot_decision_regions(X_plt, y, clf=lr)\n",
    "#plt.title('Softmax Regression - Gradient Descent')\n",
    "#plt.show()\n",
    "\n",
    "plt.plot(range(len(lr2.cost_)), lr2.cost_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834     bad\n",
       "832     bad\n",
       "435     bad\n",
       "5      good\n",
       "769    good\n",
       "679    good\n",
       "722     bad\n",
       "215    good\n",
       "653     bad\n",
       "150    good\n",
       "Name: class, dtype: category\n",
       "Categories (2, object): [good, bad]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_target_test[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 2 Class Labels: [0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr2.predict(one_hot_cols_test.values)\n",
    "print('Last 2 Class Labels: %s' % y_pred[-100:])\n",
    "len(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Validation:\n",
    "    def cross_validate(self, data, k, model, gradient_obj, test_cols): \n",
    "        \n",
    "        train_col = None\n",
    "        \n",
    "        for c in test_cols:\n",
    "            if c in data:\n",
    "                train_col = c\n",
    "                break\n",
    "        \n",
    "        shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "            \n",
    "        folds = np.array_split(shuffled_data, k)\n",
    "        \n",
    "        accuracy_sum = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            folds_to_train = folds.copy()\n",
    "            fold_to_test = folds_to_train[i]\n",
    "            del folds_to_train[i]\n",
    "            folds_to_train = pd.concat(folds_to_train, sort=False)\n",
    "            \n",
    "            x_train = folds_to_train.loc[:,folds_to_train.columns != train_col]\n",
    "            y_train = folds_to_train.loc[:,folds_to_train.columns == train_col]\n",
    "            \n",
    "            x_test = fold_to_test.loc[:,fold_to_test.columns != train_col]\n",
    "            y_test = fold_to_test.loc[:,fold_to_test.columns == train_col]\n",
    "            \n",
    "            model.fit(x_train, y_train.values.ravel(), gradient_obj)\n",
    "            predictions = model.predict(x_test.to_numpy())\n",
    "            accuracy_sum += accuracy_score(predictions, y_test.values.ravel())\n",
    "            \n",
    "        return accuracy_sum / k\n",
    "\n",
    "cross = Cross_Validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "1           0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "2           0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "3           0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "4           0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1433        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1434        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "1435        0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "1436        0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        6.0        0.0   \n",
      "1           0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
      "2           3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "3           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1432        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1433        2.0        0.0        0.0       11.0  ...        0.0        0.0   \n",
      "1434        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1435        4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1436        0.0        0.0        0.0        4.0  ...        0.0        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0           0.0        0.0        7.0       15.0       16.0       16.0   \n",
      "1           2.0       13.0       16.0       16.0       16.0        2.0   \n",
      "2           0.0       15.0       13.0        7.0        0.0        0.0   \n",
      "3           0.0        0.0       11.0        9.0        0.0        0.0   \n",
      "4           0.0        0.0       12.0       12.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        1.0        9.0       12.0       13.0        9.0        0.0   \n",
      "1433        0.0       12.0       16.0       15.0        9.0        1.0   \n",
      "1434        0.0        9.0       13.0        0.0        0.0        0.0   \n",
      "1435        0.0        6.0       16.0        4.0        0.0        0.0   \n",
      "1436        0.0        5.0       16.0       16.0       11.0        0.0   \n",
      "\n",
      "      pixel_7_7  target  \n",
      "0           6.0       6  \n",
      "1           0.0       5  \n",
      "2           0.0       3  \n",
      "3           0.0       4  \n",
      "4           0.0       4  \n",
      "...         ...     ...  \n",
      "1432        0.0       3  \n",
      "1433        0.0       3  \n",
      "1434        0.0       7  \n",
      "1435        0.0       7  \n",
      "1436        0.0       8  \n",
      "\n",
      "[1437 rows x 65 columns]\n",
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0    0.500000       0.155341                    1.00             0.75   \n",
      "1    0.333333       0.169507                    1.00             0.25   \n",
      "2    0.833333       0.402084                    1.00             0.50   \n",
      "3    0.208333       0.068606                    0.50             0.50   \n",
      "4    0.083333       0.084347                    0.25             0.50   \n",
      "..        ...            ...                     ...              ...   \n",
      "795  0.166667       0.058728                    1.00             1.00   \n",
      "796  0.375000       0.212495                    1.00             0.50   \n",
      "797  0.125000       0.207990                    0.25             1.00   \n",
      "798  0.250000       0.104646                    0.50             0.50   \n",
      "799  0.500000       0.535009                    0.25             0.75   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.400000              0.25             0.5                0        4   \n",
      "1    0.360000              0.25             0.5                1        4   \n",
      "2    0.320000              0.25             0.5                0        4   \n",
      "3    0.333333              0.25             0.5                0        4   \n",
      "4    0.320000              0.50             0.5                3        6   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "795  0.640000              0.50             0.5                1        4   \n",
      "796  0.480000              0.25             1.0                0        0   \n",
      "797  0.853333              0.25             0.5                3        2   \n",
      "798  0.413333              0.50             0.5                0        3   \n",
      "799  0.413333              0.50             1.0                0        0   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 2  ...           3                3              2   \n",
      "1                 3  ...           2                0              2   \n",
      "2                 3  ...           2                0              2   \n",
      "3                 0  ...           0                2              2   \n",
      "4                 1  ...           1                0              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "795               4  ...           0                3              2   \n",
      "796               3  ...           0                3              2   \n",
      "797               3  ...           3                3              2   \n",
      "798               1  ...           2                3              2   \n",
      "799               2  ...           1                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     2                    1        0    1              0   \n",
      "1                     1                    1        1    1              0   \n",
      "2                     1                    1        1    0              0   \n",
      "3                     1                    1        2    1              0   \n",
      "4                     0                    1        2    1              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "795                   0                    0        1    1              0   \n",
      "796                   0                    1        1    1              1   \n",
      "797                   3                    1        1    3              0   \n",
      "798                   3                    1        1    3              0   \n",
      "799                   1                    1        1    3              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 1      0  \n",
      "2                 1      0  \n",
      "3                 1      0  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "795               1      0  \n",
      "796               1      0  \n",
      "797               1      1  \n",
      "798               1      0  \n",
      "799               1      1  \n",
      "\n",
      "[800 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# set up grid testing\n",
    "\n",
    "    \n",
    "param_grid = [\n",
    "  {'learning_rate': np.arange(0.00001, 0.0001, 0.00005), 'max_iters': [250], 'random_seed':[0],\n",
    "  'alphaa': np.arange(0.001, 0.011, 0.01), 'beta1': np.arange(0.9, 0.99, 0.09), 'max_iterations': [1e4], 'max_no_change': np.arange(10,20,10), \n",
    "  'adaptive': [False], 'beta2': np.arange(0.99, 0.999, 0.009), 'epsilon': np.arange(1e-9, 1e-8, 9e-9), 'minibatch_size': np.arange(1,10, 9),\n",
    "  'regularize': [0,1,2], 'lambdaa': np.arange(0.01, 0.1, 0.09)}\n",
    "]\n",
    "\n",
    "\n",
    "#merge train and train targets, send to cross validation for each grid\n",
    "print (digits_final)\n",
    "print (credit_final)\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, learning_rate=0.01, max_iters=50, random_seed=0, alphaa=0.001, beta1=0.9, max_iterations=1e4, max_no_change=20,\n",
    "                 adaptive=False, beta2=0.999, epsilon=1e-8, minibatch_size=0, regularize=0, lambdaa=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.random_seed = random_seed\n",
    "        self.alphaa = alphaa\n",
    "        self.beta1 = beta1\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_no_change = max_no_change\n",
    "        self.adaptive = adaptive\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.regularize = regularize\n",
    "        self.lambdaa = lambdaa\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        params = {'learning_rate': self.learning_rate, 'max_iters': self.max_iters, 'random_seed':self.random_seed,\n",
    "                  'alphaa': self.alphaa, 'beta1': self.beta1, 'max_iterations': self.max_iterations, 'max_no_change': self.max_no_change, \n",
    "                  'adaptive': self.adaptive, 'beta2':self.beta2, 'epsilon': self.epsilon, 'minibatch_size': self.minibatch_size,\n",
    "                  'regularize': self.regularize, 'lambdaa': self.lambdaa}\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self,X):\n",
    "        self.lr = SoftmaxRegression(learning_rate=self.learning_rate, max_iters=self.max_iters, random_seed=self.random_seed)\n",
    "        self.gd = GradientDescent(alphaa=self.alphaa, max_iterations=self.max_iterations, max_no_change=self.max_no_change,\n",
    "                                  adaptive=self.adaptive, beta2=self.beta2, epsilon=self.epsilon, regularize=self.regularize,\n",
    "                                  lambdaa=self.lambdaa, minibatch_size=self.minibatch_size)\n",
    "        self.accuracy = cross.cross_validate(X, 5, self.lr, self.gd, ['target', 'class'])\n",
    "        print (self.accuracy)\n",
    "        return self.accuracy\n",
    "        \n",
    "    \n",
    "def test_scorer(estimator, X):\n",
    "    print (estimator.accuracy)\n",
    "    return estimator.accuracy\n",
    "\n",
    "# def tester_scorer_credit(estimator, X):\n",
    "#     error = cross.cross_validate(X, 5, estimator.lr, estimator.gd, 'class')\n",
    "#     return error\n",
    "    \n",
    "cv = [(slice(None), slice(None))] # dont use grid search cross validation, want to use our own\n",
    "gs = GridSearchCV(estimator=Tester(), param_grid=param_grid, \n",
    "                  scoring=test_scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "gs.fit(digits_final)\n",
    "#get best hyper parameters, then run test data using them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([77.75337529, 76.56331205]), 'std_fit_time': array([0., 0.]), 'mean_score_time': array([0., 0.]), 'std_score_time': array([0., 0.]), 'param_learning_rate': masked_array(data=[1e-05, 6e-05],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 1e-05}, {'learning_rate': 6e-05}], 'split0_test_score': array([0.94850707, 0.94850707]), 'mean_test_score': array([0.94850707, 0.94850707]), 'std_test_score': array([0., 0.]), 'rank_test_score': array([1, 1])}\n",
      "{'learning_rate': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print (gs.cv_results_)\n",
    "print (gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
