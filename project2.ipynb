{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "1109        0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "940         0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "192         0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "260         0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "1148        0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "835         0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1216        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1653        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "559         0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "684         0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
      "1109        0.0        0.0        0.0        0.0  ...       15.0        6.0   \n",
      "940         0.0        0.0        0.0        1.0  ...        8.0        0.0   \n",
      "192         3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "260         0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1148        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "835         0.0        0.0        0.0        2.0  ...        1.0        0.0   \n",
      "1216        2.0        0.0        0.0       11.0  ...        7.0        0.0   \n",
      "1653        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "559         4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "684         0.0        0.0        0.0        4.0  ...        1.0        0.0   \n",
      "\n",
      "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
      "1109        0.0        0.0        0.0        7.0       15.0       16.0   \n",
      "940         0.0        2.0       13.0       16.0       16.0       16.0   \n",
      "192         0.0        0.0       15.0       13.0        7.0        0.0   \n",
      "260         0.0        0.0        0.0       11.0        9.0        0.0   \n",
      "1148        0.0        0.0        0.0       12.0       12.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "835         0.0        1.0        9.0       12.0       13.0        9.0   \n",
      "1216        0.0        0.0       12.0       16.0       15.0        9.0   \n",
      "1653        0.0        0.0        9.0       13.0        0.0        0.0   \n",
      "559         0.0        0.0        6.0       16.0        4.0        0.0   \n",
      "684         0.0        0.0        5.0       16.0       16.0       11.0   \n",
      "\n",
      "      pixel_7_6  pixel_7_7  \n",
      "1109       16.0        6.0  \n",
      "940         2.0        0.0  \n",
      "192         0.0        0.0  \n",
      "260         0.0        0.0  \n",
      "1148        0.0        0.0  \n",
      "...         ...        ...  \n",
      "835         0.0        0.0  \n",
      "1216        1.0        0.0  \n",
      "1653        0.0        0.0  \n",
      "559         0.0        0.0  \n",
      "684         0.0        0.0  \n",
      "\n",
      "[1437 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "d = datasets.load_digits(as_frame=True)\n",
    "digits = d['data']\n",
    "digits_target = d['target']\n",
    "\n",
    "c = datasets.fetch_openml(name='credit-g', as_frame=True)\n",
    "credit = c['data']\n",
    "credit_target = c['target']\n",
    "\n",
    "digits, digits_test, digits_target, digits_target_test = train_test_split(digits, digits_target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "credit, credit_test, credit_target, credit_target_test = train_test_split(credit, credit_target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print (digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0      0.000     0.0000     0.5625     0.9375     0.1250   \n",
      "1           0.0      0.375     0.7500     0.7500     0.8750     0.2500   \n",
      "2           0.0      0.125     0.6250     0.9375     1.0000     0.8125   \n",
      "3           0.0      0.000     0.0000     0.7500     0.2500     0.0000   \n",
      "4           0.0      0.000     0.0000     0.5625     1.0000     0.1875   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        0.0      0.125     0.5000     0.8750     0.9375     0.1250   \n",
      "1433        0.0      0.250     0.5625     0.9375     1.0000     0.9375   \n",
      "1434        0.0      0.000     0.3125     0.8750     0.8750     0.1250   \n",
      "1435        0.0      0.000     0.2500     0.6250     0.9375     1.0000   \n",
      "1436        0.0      0.000     0.3750     0.8750     0.8125     0.2500   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0        0.0000        0.0        0.0     0.0000  ...   0.461538        0.0   \n",
      "1        0.0000        0.0        0.0     0.0625  ...   0.000000        0.0   \n",
      "2        0.1875        0.0        0.0     0.3125  ...   0.000000        0.0   \n",
      "3        0.0000        0.0        0.0     0.0000  ...   0.000000        0.0   \n",
      "4        0.0000        0.0        0.0     0.0000  ...   0.000000        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1432     0.0000        0.0        0.0     0.1250  ...   0.000000        0.0   \n",
      "1433     0.1250        0.0        0.0     0.6875  ...   0.000000        0.0   \n",
      "1434     0.0000        0.0        0.0     0.1250  ...   0.000000        0.0   \n",
      "1435     0.2500        0.0        0.0     0.0000  ...   0.000000        0.0   \n",
      "1436     0.0000        0.0        0.0     0.2500  ...   0.000000        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0      0.000000     0.0000     0.4375     0.9375     1.0000     1.0000   \n",
      "1      0.222222     0.8125     1.0000     1.0000     1.0000     0.1250   \n",
      "2      0.000000     0.9375     0.8125     0.4375     0.0000     0.0000   \n",
      "3      0.000000     0.0000     0.6875     0.5625     0.0000     0.0000   \n",
      "4      0.000000     0.0000     0.7500     0.7500     0.0000     0.0000   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432   0.111111     0.5625     0.7500     0.8125     0.5625     0.0000   \n",
      "1433   0.000000     0.7500     1.0000     0.9375     0.5625     0.0625   \n",
      "1434   0.000000     0.5625     0.8125     0.0000     0.0000     0.0000   \n",
      "1435   0.000000     0.3750     1.0000     0.2500     0.0000     0.0000   \n",
      "1436   0.000000     0.3125     1.0000     1.0000     0.6875     0.0000   \n",
      "\n",
      "      pixel_7_7  target  \n",
      "0         0.375       6  \n",
      "1         0.000       5  \n",
      "2         0.000       3  \n",
      "3         0.000       4  \n",
      "4         0.000       4  \n",
      "...         ...     ...  \n",
      "1432      0.000       3  \n",
      "1433      0.000       3  \n",
      "1434      0.000       7  \n",
      "1435      0.000       7  \n",
      "1436      0.000       8  \n",
      "\n",
      "[1437 rows x 65 columns]\n",
      "     pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0          0.0   0.000000     0.6875     1.0000     0.9375     0.1875   \n",
      "1          0.0   0.142857     0.9375     0.8750     0.1250     0.0000   \n",
      "2          0.0   0.285714     0.8125     1.0000     0.6250     0.0000   \n",
      "3          0.0   0.000000     0.5625     0.4375     0.0000     0.0000   \n",
      "4          0.0   0.000000     0.1875     0.8125     0.3750     0.0000   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "355        0.0   0.000000     0.1875     0.5000     0.6875     0.8125   \n",
      "356        0.0   0.000000     0.0000     0.5625     0.6875     0.0000   \n",
      "357        0.0   0.142857     0.5625     1.0000     1.0000     0.7500   \n",
      "358        0.0   0.000000     0.0000     0.1875     0.8750     0.8125   \n",
      "359        0.0   0.000000     0.0000     0.5625     0.8125     0.6250   \n",
      "\n",
      "     pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0       0.0000        0.0        0.0   0.357143  ...        0.0        0.0   \n",
      "1       0.0000        0.0        0.0   0.428571  ...        0.0        0.0   \n",
      "2       0.0000        0.0        0.0   0.857143  ...        0.0        0.0   \n",
      "3       0.0000        0.0        0.0   0.000000  ...        0.0        0.0   \n",
      "4       0.0000        0.0        0.0   0.000000  ...        0.0        0.0   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "355     0.8750        0.0        0.0   0.142857  ...        0.0        0.0   \n",
      "356     0.0000        0.0        0.0   0.000000  ...        0.0        0.0   \n",
      "357     0.0625        0.0        0.0   0.000000  ...        0.0        0.0   \n",
      "358     0.1875        0.0        0.0   0.000000  ...        0.0        0.0   \n",
      "359     0.0625        0.0        0.0   0.000000  ...        0.0        0.0   \n",
      "\n",
      "     pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0          0.0     0.8125     0.8125     0.5000     0.8125     1.0000   \n",
      "1          0.2     0.9375     1.0000     0.7500     0.0625     0.0000   \n",
      "2          0.2     0.8125     1.0000     1.0000     1.0000     1.0000   \n",
      "3          0.0     0.4375     0.8750     1.0000     0.7500     0.0625   \n",
      "4          0.0     0.1875     0.8125     0.9375     0.5000     0.0000   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "355        0.0     0.1250     0.7500     0.8125     0.1250     0.0000   \n",
      "356        0.0     0.0000     0.6875     0.4375     0.0000     0.0000   \n",
      "357        0.0     0.6250     1.0000     0.6875     0.2500     0.0000   \n",
      "358        0.0     0.0000     0.1875     0.8125     0.9375     0.1250   \n",
      "359        0.0     0.0000     0.6250     1.0000     0.7500     0.0000   \n",
      "\n",
      "     pixel_7_7  target  \n",
      "0       0.5000       2  \n",
      "1       0.0000       8  \n",
      "2       0.1875       2  \n",
      "3       0.0000       6  \n",
      "4       0.0000       6  \n",
      "..         ...     ...  \n",
      "355     0.0000       5  \n",
      "356     0.0000       4  \n",
      "357     0.0000       3  \n",
      "358     0.0000       8  \n",
      "359     0.0000       8  \n",
      "\n",
      "[360 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# no preprocessing needed \n",
    "df = digits.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "digits_final = pd.concat([df, digits_target], axis=1)\n",
    "digits_final.reset_index(drop=True, inplace=True)\n",
    "print (digits_final)\n",
    "\n",
    "df2 = digits_test.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "digits_test_final = pd.concat([df2, digits_target_test], axis=1)\n",
    "digits_test_final.reset_index(drop=True, inplace=True)\n",
    "print (digits_test_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0    0.500000       0.155341                    1.00             0.75   \n",
      "1    0.333333       0.169507                    1.00             0.25   \n",
      "2    0.833333       0.402084                    1.00             0.50   \n",
      "3    0.208333       0.068606                    0.50             0.50   \n",
      "4    0.083333       0.084347                    0.25             0.50   \n",
      "..        ...            ...                     ...              ...   \n",
      "795  0.166667       0.058728                    1.00             1.00   \n",
      "796  0.375000       0.212495                    1.00             0.50   \n",
      "797  0.125000       0.207990                    0.25             1.00   \n",
      "798  0.250000       0.104646                    0.50             0.50   \n",
      "799  0.500000       0.535009                    0.25             0.75   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.400000              0.25             0.5                0        4   \n",
      "1    0.360000              0.25             0.5                1        4   \n",
      "2    0.320000              0.25             0.5                0        4   \n",
      "3    0.333333              0.25             0.5                0        4   \n",
      "4    0.320000              0.50             0.5                3        6   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "795  0.640000              0.50             0.5                1        4   \n",
      "796  0.480000              0.25             1.0                0        0   \n",
      "797  0.853333              0.25             0.5                3        2   \n",
      "798  0.413333              0.50             0.5                0        3   \n",
      "799  0.413333              0.50             1.0                0        0   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 2  ...           3                3              2   \n",
      "1                 3  ...           2                0              2   \n",
      "2                 3  ...           2                0              2   \n",
      "3                 0  ...           0                2              2   \n",
      "4                 1  ...           1                0              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "795               4  ...           0                3              2   \n",
      "796               3  ...           0                3              2   \n",
      "797               3  ...           3                3              2   \n",
      "798               1  ...           2                3              2   \n",
      "799               2  ...           1                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     2                    1        0    1              0   \n",
      "1                     1                    1        1    1              0   \n",
      "2                     1                    1        1    0              0   \n",
      "3                     1                    1        2    1              0   \n",
      "4                     0                    1        2    1              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "795                   0                    0        1    1              0   \n",
      "796                   0                    1        1    1              1   \n",
      "797                   3                    1        1    3              0   \n",
      "798                   3                    1        1    3              0   \n",
      "799                   1                    1        1    3              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 1      0  \n",
      "2                 1      0  \n",
      "3                 1      0  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "795               1      0  \n",
      "796               1      0  \n",
      "797               1      1  \n",
      "798               1      0  \n",
      "799               1      1  \n",
      "\n",
      "[800 rows x 21 columns]\n",
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0        0.60       0.272003                    1.00             0.75   \n",
      "1        0.15       0.245757                    0.25             0.50   \n",
      "2        0.30       0.172793                    0.75             1.00   \n",
      "3        0.20       0.137066                    1.00             0.25   \n",
      "4        1.00       0.712195                    0.50             1.00   \n",
      "..        ...            ...                     ...              ...   \n",
      "195      0.30       0.099828                    0.75             0.25   \n",
      "196      0.20       0.084370                    1.00             0.50   \n",
      "197      0.10       0.064033                    0.25             0.75   \n",
      "198      0.60       0.555548                    0.50             1.00   \n",
      "199      0.10       0.092477                    0.50             1.00   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.461538              0.25             0.5                1        3   \n",
      "1    0.400000              0.25             1.0                3        4   \n",
      "2    0.661538              0.25             0.5                3        3   \n",
      "3    0.415385              0.25             0.5                0        4   \n",
      "4    0.646154              0.25             0.5                3        4   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "195  0.400000              0.25             0.5                3        6   \n",
      "196  0.369231              0.25             0.5                1        4   \n",
      "197  0.600000              0.50             0.5                0        8   \n",
      "198  0.646154              1.00             0.5                0        4   \n",
      "199  0.646154              0.25             1.0                3        6   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 3  ...           4                3              2   \n",
      "1                 3  ...           0                3              1   \n",
      "2                 3  ...           0                3              2   \n",
      "3                 1  ...           2                3              2   \n",
      "4                 3  ...           3                3              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "195               3  ...           2                0              2   \n",
      "196               3  ...           0                0              2   \n",
      "197               1  ...           1                0              2   \n",
      "198               2  ...           3                3              2   \n",
      "199               3  ...           3                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     1                    1        1    0              1   \n",
      "1                     3                    1        2    1              0   \n",
      "2                     3                    1        1    1              1   \n",
      "3                     0                    1        1    1              0   \n",
      "4                     1                    1        1    0              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "195                   3                    1        1    1              0   \n",
      "196                   3                    1        1    3              0   \n",
      "197                   1                    1        1    3              0   \n",
      "198                   0                    1        1    0              1   \n",
      "199                   2                    0        0    1              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 0      1  \n",
      "2                 1      1  \n",
      "3                 1      1  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "195               1      1  \n",
      "196               1      0  \n",
      "197               1      1  \n",
      "198               1      0  \n",
      "199               1      1  \n",
      "\n",
      "[200 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#everything good with data except categorical to one hot needed \n",
    "credit_cat = ['checking_status', 'purpose', 'credit_history', 'savings_status', 'employment', 'personal_status', 'other_parties',\n",
    "             'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker', 'class']\n",
    "\n",
    "def extract_columns (df, cols):\n",
    "    return df.loc[:, cols]\n",
    "\n",
    "def get_onehot (df, cat_feat):\n",
    "    categories = extract_columns(df, cat_feat)\n",
    "    le = LabelEncoder()\n",
    "    return categories.apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "merged_credit = pd.concat([credit, credit_target], axis=1)\n",
    "merged_credit.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merged_credit_test = pd.concat([credit_test, credit_target_test], axis=1)\n",
    "merged_credit_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "one_hot_cols = get_onehot(merged_credit, credit_cat)\n",
    "credit_no_cat = merged_credit.drop(credit_cat, axis = 1) \n",
    "credit_no_cat = credit_no_cat.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x))) #normalize continuous data\n",
    "credit_final = pd.concat([credit_no_cat, one_hot_cols], axis=1)\n",
    "\n",
    "\n",
    "one_hot_cols_test = get_onehot(merged_credit_test, credit_cat)\n",
    "credit_test_no_cat = merged_credit_test.drop(credit_cat, axis=1)\n",
    "credit_test_no_cat = credit_test_no_cat.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "credit_test_final = pd.concat([credit_test_no_cat, one_hot_cols_test], axis=1)\n",
    "\n",
    "#le = LabelEncoder()\n",
    "\n",
    "#credit_target = le.fit_transform(credit_target)\n",
    "#credit_target_test = le.fit_transform(credit_target_test)\n",
    "\n",
    "print (credit_final)\n",
    "print (credit_test_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optimizer class implementing minibatch gradient descent for softmax regression. Can utilize either\n",
    "    gradient descent with momentum, or Adaptive Momentum Estimation (Adam), with optional L1 or L2\n",
    "    regularization.\n",
    "\"\"\"\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
    "\n",
    "\n",
    "# Shuffles the (x,y) instances, and outputs a list of minibatch_size sized (x,y) tuples\n",
    "def minibatch(x, y, minibatch_size):\n",
    "    x, y = shuffle(x, y)\n",
    "    minibatches = []\n",
    "    if not minibatch_size:\n",
    "        minibatches.append((x, y))\n",
    "    else:\n",
    "        for i in range(0, x.shape[0], minibatch_size):\n",
    "            x_mini = x[i:i+minibatch_size]\n",
    "            y_mini = y[i:i+minibatch_size]\n",
    "            minibatches.append((x_mini, y_mini))\n",
    "    return minibatches\n",
    "\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(y, yh):\n",
    "    B = np.where(yh.ravel() >= 0.5, 1, 0)\n",
    "    return np.mean(y.ravel() == B)\n",
    "\n",
    "\n",
    "# Returns the index of the maximum value in a list\n",
    "def argmax(lst):\n",
    "    return lst.index(max(lst))\n",
    "\n",
    "\n",
    "class GradientDescent:\n",
    "\n",
    "    \"\"\"\n",
    "    Class fields:\n",
    "       alphaa - learning rate of the optimizer\n",
    "       beta1 - momentum hyperparameter\n",
    "       max_iterations - gradient descent termination condition: maximum times iterated\n",
    "       max_no_change - gradient descent termination condition: maximum number of iterations\n",
    "                         without the validation error decreasing\n",
    "       minibatch_size - size of the minibatch to use (default value of 0 indicates use full batch)\n",
    "       cost_fn - optional cost function, if included optimizer will calculate and store the\n",
    "                    training and validation cost at each iteration\n",
    "       adaptive - if true, optimizer uses Adam (Adaptive Moment Estimation) rather than gradient\n",
    "                    descent with momentum\n",
    "       beta2 - 2nd hyperparameter for Adam (if using)\n",
    "       epsilon - 3rd hyperparameter for Adam (if using), just to avoid numerical issues\n",
    "       regularize - determines regularization used (if any): 0 indicates no regularization, 1 or 2\n",
    "                      indicate L1 or L2 regularization respectively\n",
    "       lambdaa - regularization coefficient if used\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(self, alphaa=0.01, beta1=0.9, max_iterations=1e4, max_no_change=20, minibatch_size=0,\n",
    "                 cost_fn=None, adaptive=False, beta2=0.999, epsilon=1e-8, regularize=0, lambdaa=0.1):\n",
    "\n",
    "        self.alphaa = alphaa\n",
    "        self.beta1 = beta1\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_no_change = max_no_change\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.cost_fn = cost_fn\n",
    "\n",
    "        self.adaptive = adaptive\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.regularize = regularize\n",
    "        self.lambdaa = lambdaa\n",
    "\n",
    "        self.accuracy_tr = []\n",
    "        self.accuracy_val = []\n",
    "        self.weight_history = []\n",
    "        if self.cost_fn:\n",
    "            self.cost_tr = []\n",
    "            self.cost_val = []\n",
    "\n",
    "    # Run method - delegates work to one of 2 helper methods, dependent on if Adam is being used or not\n",
    "    def run(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        if self.adaptive:\n",
    "            return self.adam(x_tr, y_tr, x_val, y_val, w)\n",
    "        else:\n",
    "            return self.momentum(x_tr, y_tr, x_val, y_val, w)\n",
    "\n",
    "    # Gradient Descent with Momentum\n",
    "    def momentum(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        t = 1\n",
    "        i = 0\n",
    "        delta_w = 0\n",
    "\n",
    "        self.accuracy_tr.append(accuracy(y_tr, softmax(np.dot(x_tr, w))))\n",
    "        self.accuracy_val.append(accuracy(y_val, softmax(np.dot(x_val, w))))\n",
    "        self.weight_history.append(w)\n",
    "\n",
    "        while i < self.max_no_change and t < self.max_iterations:\n",
    "            for (x_mini, y_mini) in minibatch(x_tr, y_tr, self.minibatch_size):\n",
    "                grad = self.gradient(x_mini, y_mini, w)\n",
    "                delta_w = (self.beta1 * delta_w) + ((1 - self.beta1) * grad)\n",
    "                w -= self.alphaa * delta_w\n",
    "\n",
    "            self.weight_history.append(w)\n",
    "            tr_pred = softmax(np.dot(x_tr, w))\n",
    "            pred = softmax(np.dot(x_val, w))\n",
    "            self.accuracy_tr.append(accuracy(y_tr, tr_pred))\n",
    "            self.accuracy_val.append(accuracy(y_val, pred))\n",
    "            if self.cost_fn:\n",
    "                self.cost_tr.append(self.cost_fn(y_tr, tr_pred))\n",
    "                self.cost_val.append(self.cost_fn(y_val, pred))\n",
    "\n",
    "            if not self.accuracy_val[-1] < self.accuracy_val[-2]:\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "            t += 1\n",
    "        return self.weight_history[argmax(self.accuracy_val)]\n",
    "\n",
    "    # Adaptive Moment Estimation\n",
    "    def adam(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        t = 1\n",
    "        i = 0\n",
    "        m = 0\n",
    "        s = 0\n",
    "\n",
    "        self.accuracy_tr.append(accuracy(y_tr, softmax(np.dot(x_tr, w))))\n",
    "        self.accuracy_val.append(accuracy(y_val, softmax(np.dot(x_val, w))))\n",
    "        self.weight_history.append(w)\n",
    "\n",
    "        while i < self.max_no_change and t < self.max_iterations:\n",
    "            for (x_mini, y_mini) in minibatch(x_tr, y_tr, self.minibatch_size):\n",
    "                grad = self.gradient(x_mini, y_mini, w)\n",
    "                m = (self.beta1 * m) + ((1 - self.beta1) * grad)\n",
    "                s = (self.beta2 * s) + ((1 - self.beta2) * np.power(grad, 2))\n",
    "                mh = m / (1 - np.power(self.beta1, t))\n",
    "                sh = s / (1 - np.power(self.beta2, t))\n",
    "                w -= self.alphaa * mh * grad / (np.sqrt(sh) + self.epsilon)\n",
    "\n",
    "            self.weight_history.append(w)\n",
    "            tr_pred = softmax(np.dot(x_tr, w))\n",
    "            pred = softmax(np.dot(x_val, w))\n",
    "            self.accuracy_tr.append(accuracy(y_tr, tr_pred))\n",
    "            self.accuracy_val.append(accuracy(y_val, pred))\n",
    "            if self.cost_fn:\n",
    "                self.cost_tr.append(self.cost_fn(y_tr, tr_pred))\n",
    "                self.cost_val.append(self.cost_fn(y_val, pred))\n",
    "\n",
    "            if not self.accuracy_val[-1] < self.accuracy_val[-2]:\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "            t += 1\n",
    "        return self.weight_history[argmax(self.accuracy_val)]\n",
    "\n",
    "    # Helper method to calculate gradient (and add regularization penalty if any)\n",
    "    def gradient(self, x, y, w):\n",
    "        n, d = x.shape\n",
    "        yh = softmax(np.dot(x, w))\n",
    "\n",
    "        grad = np.dot(x.T, yh - y) / n\n",
    "        if self.regularize == 1:\n",
    "            grad[1:] += self.lambdaa * np.sign(w[1:])\n",
    "        elif self.regularize == 2:\n",
    "            grad[1:] += self.lambdaa * w[1:]\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from .._base import _BaseClassifier\n",
    "#from .._base import _BaseMultiClass\n",
    "\n",
    "\n",
    "class SoftmaxRegression(object):\n",
    "\n",
    "    \"\"\"Softmax regression classifier.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, max_iters=50,\n",
    "                 l2=0.0,\n",
    "                 minibatches=1,\n",
    "                 n_classes=None):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.l2 = l2\n",
    "        self.minibatches = minibatches\n",
    "        self.n_classes = n_classes\n",
    "        self.random_seed = 0\n",
    "\n",
    "\n",
    "    def fit(self, X_tr, y_tr, X_val, y_val, gd):\n",
    "        \n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "  \n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = np.max(y_tr) + 1\n",
    "        self._n_features = X_tr.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"Initialize weight coefficients.\"\"\"\n",
    "        np.random.seed(self.random_seed)\n",
    "        self.w_ = np.random.normal(loc=0.0, scale=0.01, size=(self._n_features, self.n_classes)).astype('float64')\n",
    "        self.cost_ = []\n",
    "\n",
    "        y_tr_enc = self._one_hot(y=y_tr, n_labels=self.n_classes, dtype=np.float)\n",
    "        y_val_enc = self._one_hot(y=y_val, n_labels=self.n_classes, dtype=np.float)\n",
    "\n",
    "     \n",
    "        for i in range(self.max_iters):\n",
    "           \n",
    "            \n",
    "            #GRADIENT DESCENT line below (make sure to split X, y into training and validation sets)\n",
    "            \n",
    "            self._w = gd.run(X_tr,y_tr_enc,X_val,y_val_enc,self.w_)\n",
    "            \n",
    "            #COMMENT THE FOR LOOP BELOW\n",
    "\n",
    "            \"\"\" \n",
    "            for idx in self._yield_minibatches_idx(\n",
    "                    n_batches=self.minibatches,\n",
    "                    data_ary=y,\n",
    "                    shuffle=True):\n",
    "                # givens:\n",
    "                # w_ -> n_feat x n_classes\n",
    "                # b_  -> n_classes\n",
    "                \n",
    "                # net_input, softmax and diff -> n_samples x n_classes:\n",
    "                net = X[idx].dot(self.w_) #net_input\n",
    "                softm = self.softmax(net) \n",
    "                diff = softm - y_enc[idx]\n",
    "                mse = np.mean(diff, axis=0)\n",
    "\n",
    "                # gradient -> n_features x n_classes\n",
    "                grad = np.dot(X[idx].T, diff)\n",
    "                \n",
    "                # update in opp. direction of the cost gradient\n",
    "                self.w_ -= (self.eta * grad +\n",
    "                            self.eta * self.l2 * self.w_)  \n",
    "            \n",
    "            \"\"\"  \n",
    "            # compute cost of the whole epoch\n",
    "            net = X_tr.dot(self.w_)\n",
    "            softm = self.softmax(net)\n",
    "            cross_ent = self.cross_entropy(output=softm, y_target=y_tr_enc)\n",
    "            cost = self.cost(cross_ent)\n",
    "            self.cost_.append(cost)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        #Predict targets from X.\n",
    "\n",
    "        net = X.dot(self.w_)\n",
    "        probas = self.softmax(net)\n",
    "        return probas.argmax(axis=1)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
    "\n",
    "\n",
    "    def cross_entropy(self, output, y_target):\n",
    "        return - np.sum(np.log(output) * (y_target), axis=1)\n",
    "\n",
    "    def cost(self, cross_entropy):\n",
    "        L2_term = self.l2 * np.sum(self.w_ ** 2)\n",
    "        cross_entropy = cross_entropy + L2_term\n",
    "        return 0.5 * np.mean(cross_entropy)\n",
    "\n",
    "\n",
    "    def _one_hot(self, y, n_labels, dtype):\n",
    "        mat = np.zeros((len(y), n_labels))\n",
    "        for i, val in enumerate(y):\n",
    "            mat[i, val] = 1\n",
    "        return mat.astype(dtype)    \n",
    "    \n",
    "    def _yield_minibatches_idx(self, n_batches, data_ary, shuffle=True):\n",
    "            indices = np.arange(data_ary.shape[0])\n",
    "\n",
    "            if shuffle:\n",
    "                indices = np.random.permutation(indices)\n",
    "            if n_batches > 1:\n",
    "                remainder = data_ary.shape[0] % n_batches\n",
    "\n",
    "                if remainder:\n",
    "                    minis = np.array_split(indices[:-remainder], n_batches)\n",
    "                    minis[-1] = np.concatenate((minis[-1],\n",
    "                                                indices[-remainder:]),\n",
    "                                               axis=0)\n",
    "                else:\n",
    "                    minis = np.array_split(indices, n_batches)\n",
    "\n",
    "            else:\n",
    "                minis = (indices,)\n",
    "\n",
    "            for idx_batch in minis:\n",
    "                yield idx_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-045daa063471>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSoftmaxRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientDescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# #X_plt = X[:, [0,1]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c47edded7def>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_tr, y_tr, X_val, y_val, gd)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;31m# compute cost of the whole epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0msoftm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mcross_ent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoftm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_tr_enc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_ent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c47edded7def>\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[0mpass_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[0mpass_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpass_op\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_logical\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             return _combine_series_frame(\n\u001b[0m\u001b[0;32m    776\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpass_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36m_combine_series_frame\u001b[1;34m(self, other, func, fill_value, axis, level)\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_match_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m         \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch_to_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mdispatch_to_series\u001b[1;34m(left, right, func, str_rep, axis)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m     \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, op_str, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[0muse_numexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mcolumn_op\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mcolumn_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mcolumn_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op, str_rep)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[1;34m(left, right, op, str_rep)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, op_str, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[0muse_numexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0m_can_use_numexpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"evaluate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0mis_reversed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_reversed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_can_use_numexpr\u001b[1;34m(op, op_str, a, b, dtype_check)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m# required min elements (otherwise we are adding overhead)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MIN_ELEMENTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[1;31m# check for dtype compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mdtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2959\u001b[0m     \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m     \"\"\"\n\u001b[1;32m-> 2961\u001b[1;33m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[0;32m   2962\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[0;32m     75\u001b[0m                   if v is not np._NoValue}\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[0;32m     75\u001b[0m                   if v is not np._NoValue}\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading Data\n",
    "\n",
    "\n",
    "x_train = digits_final.loc[:,digits_final.columns != \"target\"]\n",
    "y_train = digits_final.loc[:,digits_final.columns == \"target\"]\n",
    "\n",
    "x_test = digits_test_final.loc[:,digits_test_final.columns != \"target\"]\n",
    "y_test = digits_test_final.loc[:,digits_test_final.columns == \"target\"]\n",
    "\n",
    "\n",
    "#standardize\n",
    "# X[:,0] = X[:,0] / np.amax(X[:,0])\n",
    "# X[:,1] = X[:,1] / np.amax(X[:,1])\n",
    "\n",
    "\n",
    "lr = SoftmaxRegression(learning_rate=0.00001, max_iters=250, minibatches=1)\n",
    "gd = GradientDescent()\n",
    "lr.fit(x_train, y_train.values.ravel(), x_test, y_test.values.ravel(), gd)\n",
    "\n",
    "# #X_plt = X[:, [0,1]]\n",
    "\n",
    "# #plot_decision_regions(X_plt, y, clf=lr)\n",
    "# #plt.title('Softmax Regression - Gradient Descent')\n",
    "# #plt.show()\n",
    "\n",
    "plt.plot(range(len(lr.cost_)), lr.cost_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1419-4f0a6917930f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdigits_target_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "digits_target_test.values[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 2 Class Labels: [2 8 2 6 6 7 1 9 8 5 2 8 6 6 6 6 1 0 5 8 8 7 8 4 7 5 4 9 2 9 4 7 6 8 9 4 3\n",
      " 1 0 1 8 6 7 7 9 0 7 6 2 1 9 6 7 9 0 0 9 1 6 3 0 2 3 4 1 9 7 6 9 1 8 3 5 1\n",
      " 2 1 2 2 9 7 2 3 6 0 5 3 7 5 1 2 9 9 3 1 7 7 4 8 5 8 5 5 2 5 9 0 7 1 4 7 3\n",
      " 4 8 9 7 7 8 0 1 9 2 5 8 4 1 7 0 6 1 5 9 9 9 5 9 9 5 7 5 6 2 8 6 9 6 1 5 1\n",
      " 5 9 9 1 5 3 6 1 8 9 7 7 6 7 6 5 6 0 8 8 9 3 6 1 0 7 1 6 3 8 6 7 4 9 6 3 0\n",
      " 3 3 3 0 7 7 5 7 8 0 7 8 9 6 4 5 0 1 4 6 4 3 3 0 9 5 9 3 9 4 7 1 6 8 9 2 4\n",
      " 9 3 7 6 2 3 3 1 6 9 3 6 3 3 2 0 7 6 1 1 3 7 2 7 1 5 5 7 5 2 2 7 2 7 5 5 7\n",
      " 0 9 1 6 5 9 7 4 3 8 0 3 6 4 6 3 2 6 8 8 8 4 6 7 5 2 4 5 3 2 4 6 9 4 5 4 3\n",
      " 4 6 2 9 0 6 7 2 0 9 6 0 4 2 0 7 5 8 5 7 8 2 8 4 3 7 2 6 5 9 5 1 0 8 2 5 9\n",
      " 5 6 8 2 7 2 1 5 1 6 4 5 0 9 4 1 1 7 0 8 9 0 5 4 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = lr.predict(digits_test.values)\n",
    "print('Last 2 Class Labels: %s' % y_pred[0:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.15534086 1.         ... 1.         0.         1.        ]\n",
      " [0.33333333 0.16950716 1.         ... 1.         0.         1.        ]\n",
      " [0.83333333 0.40208424 1.         ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.125      0.20798958 0.25       ... 3.         0.         1.        ]\n",
      " [0.25       0.10464611 0.5        ... 3.         0.         1.        ]\n",
      " [0.5        0.53500868 0.25       ... 3.         1.         1.        ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() missing 2 required positional arguments: 'y_val' and 'gd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1420-94ef20f86fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSoftmaxRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 2 required positional arguments: 'y_val' and 'gd'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading Data\n",
    "\n",
    "x_train = credit_final.loc[:,credit_final.columns != \"class\"]\n",
    "y_train = credit_final.loc[:,credit_final.columns == \"class\"]\n",
    "\n",
    "print (x_train.to_numpy())\n",
    "\n",
    "# df = pd.DataFrame(x_train)\n",
    "# df = df.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "\n",
    "lr2 = SoftmaxRegression(learning_rate=0.00001, max_iters=250, minibatches=1)\n",
    "gd = GradientDescent()\n",
    "lr2.fit(x_train.to_numpy(), y_train.values.ravel(), gd)\n",
    "\n",
    "print (x_train)\n",
    "#X_plt = X[:, [0,1]]\n",
    "\n",
    "#plot_decision_regions(X_plt, y, clf=lr)\n",
    "#plt.title('Softmax Regression - Gradient Descent')\n",
    "#plt.show()\n",
    "\n",
    "plt.plot(range(len(lr2.cost_)), lr2.cost_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834     bad\n",
       "832     bad\n",
       "435     bad\n",
       "5      good\n",
       "769    good\n",
       "679    good\n",
       "722     bad\n",
       "215    good\n",
       "653     bad\n",
       "150    good\n",
       "Name: class, dtype: category\n",
       "Categories (2, object): [good, bad]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_target_test[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 2 Class Labels: [0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr2.predict(one_hot_cols_test.values)\n",
    "print('Last 2 Class Labels: %s' % y_pred[-100:])\n",
    "len(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Validation:\n",
    "    def cross_validate(self, data, k, model, gradient_obj, test_cols): \n",
    "        \n",
    "        train_col = None\n",
    "        \n",
    "        for c in test_cols:\n",
    "            if c in data:\n",
    "                train_col = c\n",
    "                break\n",
    "        \n",
    "        shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "            \n",
    "        folds = np.array_split(shuffled_data, k)\n",
    "        \n",
    "        accuracy_sum = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            folds_to_train = folds.copy()\n",
    "            fold_to_test = folds_to_train[i]\n",
    "            del folds_to_train[i]\n",
    "            folds_to_train = pd.concat(folds_to_train, sort=False)\n",
    "            \n",
    "            x_train = folds_to_train.loc[:,folds_to_train.columns != train_col]\n",
    "            y_train = folds_to_train.loc[:,folds_to_train.columns == train_col]\n",
    "            \n",
    "            x_test = fold_to_test.loc[:,fold_to_test.columns != train_col]\n",
    "            y_test = fold_to_test.loc[:,fold_to_test.columns == train_col]\n",
    "            \n",
    "            model.fit(x_train, y_train.values.ravel(), x_test, y_test.values.ravel(), gradient_obj)\n",
    "            predictions = model.predict(x_test.to_numpy())\n",
    "            accuracy_sum += accuracy_score(predictions, y_test.values.ravel())\n",
    "            \n",
    "        return accuracy_sum / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# set up grid testing\n",
    "\n",
    "\n",
    "# param_grid = [\n",
    "#   {'learning_rate': np.arange(0.00001, 0.0001, 0.00005), 'max_iters': [250], 'random_seed':[0],\n",
    "#   'alphaa': np.arange(0.001, 0.011, 0.01), 'beta1': np.arange(0.9, 0.99, 0.09), 'max_iterations': [1e4], 'max_no_change': np.arange(10,20,10), \n",
    "#   'adaptive': [False], 'beta2': np.arange(0.99, 0.999, 0.009), 'epsilon': np.arange(1e-9, 1e-8, 9e-9), 'minibatch_size': np.arange(1,10, 9),\n",
    "#   'regularize': [0,1,2], 'lambdaa': np.arange(0.01, 0.1, 0.09)}\n",
    "# ]\n",
    "\n",
    "\n",
    "#merge train and train targets, send to cross validation for each grid\n",
    "# print (digits_final)\n",
    "# print (credit_final)\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, learning_rate=0.01, max_iters=50, alphaa=0.001, beta1=0.9, max_iterations=1e4, max_no_change=20,\n",
    "                 adaptive=False, beta2=0.999, epsilon=1e-8, minibatch_size=0, regularize=0, lambdaa=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.alphaa = alphaa\n",
    "        self.beta1 = beta1\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_no_change = max_no_change\n",
    "        self.adaptive = adaptive\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.regularize = regularize\n",
    "        self.lambdaa = lambdaa\n",
    "        self.minibatch_size = minibatch_size    \n",
    "    \n",
    "#     def get_params(self, deep=True):\n",
    "#         # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "#         params = {'learning_rate': self.learning_rate, 'max_iters': self.max_iters, 'random_seed':self.random_seed,\n",
    "#                   'alphaa': self.alphaa, 'beta1': self.beta1, 'max_iterations': self.max_iterations, 'max_no_change': self.max_no_change, \n",
    "#                   'adaptive': self.adaptive, 'beta2':self.beta2, 'epsilon': self.epsilon, 'minibatch_size': self.minibatch_size,\n",
    "#                   'regularize': self.regularize, 'lambdaa': self.lambdaa}\n",
    "#         return params\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self,X):\n",
    "        self.lr = SoftmaxRegression(learning_rate=self.learning_rate, max_iters=self.max_iters)\n",
    "        self.gd = GradientDescent(alphaa=self.alphaa, max_iterations=self.max_iterations, max_no_change=self.max_no_change,\n",
    "                                  adaptive=self.adaptive, beta2=self.beta2, epsilon=self.epsilon, regularize=self.regularize,\n",
    "                                  lambdaa=self.lambdaa, minibatch_size=self.minibatch_size)\n",
    "        self.accuracy = cross.cross_validate(X, 5, self.lr, self.gd, ['target', 'class'])\n",
    "        print (self.accuracy)\n",
    "        return self.accuracy\n",
    "        \n",
    "    \n",
    "# def test_scorer(estimator, X):\n",
    "#     print (estimator.accuracy)\n",
    "#     return estimator.accuracy\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "max_iters = [250]\n",
    "alphas = [0.01, 0.1]\n",
    "beta1s = [0.99, 0.9]\n",
    "max_iterations = [1e4]\n",
    "max_no_changes = [20]\n",
    "adaptives = [False]\n",
    "beta2s = [0.99]\n",
    "epsilons = [1e-8]\n",
    "minibatch_sizes = minibatch_sizes = [1,10]\n",
    "regularizes = [0]\n",
    "lambdas = [0.1]\n",
    "\n",
    "combos = np.array(np.meshgrid(learning_rates, max_iters, alphas, beta1s, max_iterations, max_no_changes, adaptives, beta2s,\n",
    "               epsilons, minibatch_sizes, regularizes, lambdas)).T.reshape(-1, 12)\n",
    "\n",
    "print (len(combos))\n",
    "cross = Cross_Validation()\n",
    "\n",
    "class GridSearcher:    \n",
    "    def grid_search(self, data, combinations):\n",
    "        t = None\n",
    "        max_accuracy = 0\n",
    "        min_time = 0\n",
    "\n",
    "        self.accuracies = []\n",
    "        self.train_times = []\n",
    "\n",
    "        for row in combos:\n",
    "            if t is None:\n",
    "                t = Tester(learning_rate=row[0], max_iters=int(row[1]), alphaa=row[2], beta1=row[3], max_iterations=int(row[4]),\n",
    "                          max_no_change=int(row[5]), adaptive=row[6], beta2=row[7], epsilon=row[8], minibatch_size=int(row[9]), regularize=int(row[10]),\n",
    "                          lambdaa=row[11])\n",
    "            else:\n",
    "                t.set_params(learning_rate=row[0], max_iters=int(row[1]), alphaa=row[2], beta1=row[3], max_iterations=int(row[4]),\n",
    "                          max_no_change=int(row[5]), adaptive=row[6], beta2=row[7], epsilon=row[8], minibatch_size=int(row[9]), regularize=int(row[10]),\n",
    "                          lambdaa=row[11])\n",
    "            start_time = time.time()\n",
    "            accuracy = t.fit(data)\n",
    "            run_time = time.time() - start_time\n",
    "            \n",
    "            self.accuracies.append(accuracy)\n",
    "            self.train_times.append(run_time)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def tester_scorer_credit(estimator, X):\n",
    "#     error = cross.cross_validate(X, 5, estimator.lr, estimator.gd, 'class')\n",
    "#     return error\n",
    "\n",
    "# cv = [(slice(None), slice(None))] # dont use grid search cross validation, want to use our own\n",
    "# gs = GridSearchCV(estimator=Tester(), param_grid=param_grid, \n",
    "#                   scoring=test_scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "# gs.fit(digits_final)\n",
    "#get best hyper parameters, then run test data using them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = GridSearcher()\n",
    "g2.grid_search(credit_final, combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 0.00e+00 1.00e-02]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 0.00e+00 1.00e-02]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 0.00e+00 1.00e-02]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 0.00e+00 1.00e-02]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 1.00e+00 1.00e-02]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 1.00e+00 1.00e-02]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 1.00e+00 1.00e-02]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 1.00e+00 1.00e-02]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 2.00e+00 1.00e-02]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 2.00e+00 1.00e-02]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 2.00e+00 1.00e-02]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 2.00e+00 1.00e-02]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 0.00e+00 1.00e-01]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 0.00e+00 1.00e-01]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 0.00e+00 1.00e-01]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 0.00e+00 1.00e-01]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 1.00e+00 1.00e-01]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 1.00e+00 1.00e-01]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 1.00e+00 1.00e-01]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 1.00e+00 1.00e-01]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 2.00e+00 1.00e-01]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.90e-01 1.00e-09 1.00e+00 2.00e+00 1.00e-01]\n",
      " [1.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 2.00e+00 1.00e-01]\n",
      " [6.00e-05 2.50e+02 0.00e+00 1.00e-03 9.00e-01 1.00e+04 1.00e+01 0.00e+00\n",
      "  9.99e-01 1.00e-09 1.00e+00 2.00e+00 1.00e-01]]\n"
     ]
    }
   ],
   "source": [
    "g = GridSearcher()\n",
    "g.grid_search(digits_final, combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
