{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "1109        0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "940         0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "192         0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "260         0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "1148        0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "835         0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1216        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1653        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "559         0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "684         0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
      "1109        0.0        0.0        0.0        0.0  ...       15.0        6.0   \n",
      "940         0.0        0.0        0.0        1.0  ...        8.0        0.0   \n",
      "192         3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "260         0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1148        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "835         0.0        0.0        0.0        2.0  ...        1.0        0.0   \n",
      "1216        2.0        0.0        0.0       11.0  ...        7.0        0.0   \n",
      "1653        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "559         4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "684         0.0        0.0        0.0        4.0  ...        1.0        0.0   \n",
      "\n",
      "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
      "1109        0.0        0.0        0.0        7.0       15.0       16.0   \n",
      "940         0.0        2.0       13.0       16.0       16.0       16.0   \n",
      "192         0.0        0.0       15.0       13.0        7.0        0.0   \n",
      "260         0.0        0.0        0.0       11.0        9.0        0.0   \n",
      "1148        0.0        0.0        0.0       12.0       12.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "835         0.0        1.0        9.0       12.0       13.0        9.0   \n",
      "1216        0.0        0.0       12.0       16.0       15.0        9.0   \n",
      "1653        0.0        0.0        9.0       13.0        0.0        0.0   \n",
      "559         0.0        0.0        6.0       16.0        4.0        0.0   \n",
      "684         0.0        0.0        5.0       16.0       16.0       11.0   \n",
      "\n",
      "      pixel_7_6  pixel_7_7  \n",
      "1109       16.0        6.0  \n",
      "940         2.0        0.0  \n",
      "192         0.0        0.0  \n",
      "260         0.0        0.0  \n",
      "1148        0.0        0.0  \n",
      "...         ...        ...  \n",
      "835         0.0        0.0  \n",
      "1216        1.0        0.0  \n",
      "1653        0.0        0.0  \n",
      "559         0.0        0.0  \n",
      "684         0.0        0.0  \n",
      "\n",
      "[1437 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "d = datasets.load_digits(as_frame=True)\n",
    "digits = d['data']\n",
    "digits_target = d['target']\n",
    "\n",
    "c = datasets.fetch_openml(name='credit-g', as_frame=True)\n",
    "credit = c['data']\n",
    "credit_target = c['target']\n",
    "\n",
    "digits, digits_test, digits_target, digits_target_test = train_test_split(digits, digits_target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "credit, credit_test, credit_target, credit_target_test = train_test_split(credit, credit_target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print (digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        0.0        9.0       15.0        2.0   \n",
      "1           0.0        3.0       12.0       12.0       14.0        4.0   \n",
      "2           0.0        1.0       10.0       15.0       16.0       13.0   \n",
      "3           0.0        0.0        0.0       12.0        4.0        0.0   \n",
      "4           0.0        0.0        0.0        9.0       16.0        3.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        0.0        1.0        8.0       14.0       15.0        2.0   \n",
      "1433        0.0        2.0        9.0       15.0       16.0       15.0   \n",
      "1434        0.0        0.0        5.0       14.0       14.0        2.0   \n",
      "1435        0.0        0.0        4.0       10.0       15.0       16.0   \n",
      "1436        0.0        0.0        6.0       14.0       13.0        4.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        6.0        0.0   \n",
      "1           0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
      "2           3.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "3           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1432        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1433        2.0        0.0        0.0       11.0  ...        0.0        0.0   \n",
      "1434        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "1435        4.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1436        0.0        0.0        0.0        4.0  ...        0.0        0.0   \n",
      "\n",
      "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0           0.0        0.0        7.0       15.0       16.0       16.0   \n",
      "1           2.0       13.0       16.0       16.0       16.0        2.0   \n",
      "2           0.0       15.0       13.0        7.0        0.0        0.0   \n",
      "3           0.0        0.0       11.0        9.0        0.0        0.0   \n",
      "4           0.0        0.0       12.0       12.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1432        1.0        9.0       12.0       13.0        9.0        0.0   \n",
      "1433        0.0       12.0       16.0       15.0        9.0        1.0   \n",
      "1434        0.0        9.0       13.0        0.0        0.0        0.0   \n",
      "1435        0.0        6.0       16.0        4.0        0.0        0.0   \n",
      "1436        0.0        5.0       16.0       16.0       11.0        0.0   \n",
      "\n",
      "      pixel_7_7  target  \n",
      "0           6.0       6  \n",
      "1           0.0       5  \n",
      "2           0.0       3  \n",
      "3           0.0       4  \n",
      "4           0.0       4  \n",
      "...         ...     ...  \n",
      "1432        0.0       3  \n",
      "1433        0.0       3  \n",
      "1434        0.0       7  \n",
      "1435        0.0       7  \n",
      "1436        0.0       8  \n",
      "\n",
      "[1437 rows x 65 columns]\n",
      "     pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0          0.0        0.0       11.0       16.0       15.0        3.0   \n",
      "1          0.0        1.0       15.0       14.0        2.0        0.0   \n",
      "2          0.0        2.0       13.0       16.0       10.0        0.0   \n",
      "3          0.0        0.0        9.0        7.0        0.0        0.0   \n",
      "4          0.0        0.0        3.0       13.0        6.0        0.0   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "355        0.0        0.0        3.0        8.0       11.0       13.0   \n",
      "356        0.0        0.0        0.0        9.0       11.0        0.0   \n",
      "357        0.0        1.0        9.0       16.0       16.0       12.0   \n",
      "358        0.0        0.0        0.0        3.0       14.0       13.0   \n",
      "359        0.0        0.0        0.0        9.0       13.0       10.0   \n",
      "\n",
      "     pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
      "0          0.0        0.0        0.0        5.0  ...        0.0        0.0   \n",
      "1          0.0        0.0        0.0        6.0  ...        0.0        0.0   \n",
      "2          0.0        0.0        0.0       12.0  ...        0.0        0.0   \n",
      "3          0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "4          0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "355       14.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
      "356        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "357        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "358        3.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "359        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "\n",
      "     pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
      "0          0.0       13.0       13.0        8.0       13.0       16.0   \n",
      "1          1.0       15.0       16.0       12.0        1.0        0.0   \n",
      "2          1.0       13.0       16.0       16.0       16.0       16.0   \n",
      "3          0.0        7.0       14.0       16.0       12.0        1.0   \n",
      "4          0.0        3.0       13.0       15.0        8.0        0.0   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "355        0.0        2.0       12.0       13.0        2.0        0.0   \n",
      "356        0.0        0.0       11.0        7.0        0.0        0.0   \n",
      "357        0.0       10.0       16.0       11.0        4.0        0.0   \n",
      "358        0.0        0.0        3.0       13.0       15.0        2.0   \n",
      "359        0.0        0.0       10.0       16.0       12.0        0.0   \n",
      "\n",
      "     pixel_7_7  target  \n",
      "0          8.0       2  \n",
      "1          0.0       8  \n",
      "2          3.0       2  \n",
      "3          0.0       6  \n",
      "4          0.0       6  \n",
      "..         ...     ...  \n",
      "355        0.0       5  \n",
      "356        0.0       4  \n",
      "357        0.0       3  \n",
      "358        0.0       8  \n",
      "359        0.0       8  \n",
      "\n",
      "[360 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# no preprocessing needed \n",
    "\n",
    "digits_final = pd.concat([digits, digits_target], axis=1)\n",
    "digits_final.reset_index(drop=True, inplace=True)\n",
    "print (digits_final)\n",
    "\n",
    "digits_test_final = pd.concat([digits_test, digits_target_test], axis=1)\n",
    "digits_test_final.reset_index(drop=True, inplace=True)\n",
    "print (digits_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0    0.500000       0.155341                    1.00             0.75   \n",
      "1    0.333333       0.169507                    1.00             0.25   \n",
      "2    0.833333       0.402084                    1.00             0.50   \n",
      "3    0.208333       0.068606                    0.50             0.50   \n",
      "4    0.083333       0.084347                    0.25             0.50   \n",
      "..        ...            ...                     ...              ...   \n",
      "795  0.166667       0.058728                    1.00             1.00   \n",
      "796  0.375000       0.212495                    1.00             0.50   \n",
      "797  0.125000       0.207990                    0.25             1.00   \n",
      "798  0.250000       0.104646                    0.50             0.50   \n",
      "799  0.500000       0.535009                    0.25             0.75   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.400000              0.25             0.5                0        4   \n",
      "1    0.360000              0.25             0.5                1        4   \n",
      "2    0.320000              0.25             0.5                0        4   \n",
      "3    0.333333              0.25             0.5                0        4   \n",
      "4    0.320000              0.50             0.5                3        6   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "795  0.640000              0.50             0.5                1        4   \n",
      "796  0.480000              0.25             1.0                0        0   \n",
      "797  0.853333              0.25             0.5                3        2   \n",
      "798  0.413333              0.50             0.5                0        3   \n",
      "799  0.413333              0.50             1.0                0        0   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 2  ...           3                3              2   \n",
      "1                 3  ...           2                0              2   \n",
      "2                 3  ...           2                0              2   \n",
      "3                 0  ...           0                2              2   \n",
      "4                 1  ...           1                0              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "795               4  ...           0                3              2   \n",
      "796               3  ...           0                3              2   \n",
      "797               3  ...           3                3              2   \n",
      "798               1  ...           2                3              2   \n",
      "799               2  ...           1                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     2                    1        0    1              0   \n",
      "1                     1                    1        1    1              0   \n",
      "2                     1                    1        1    0              0   \n",
      "3                     1                    1        2    1              0   \n",
      "4                     0                    1        2    1              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "795                   0                    0        1    1              0   \n",
      "796                   0                    1        1    1              1   \n",
      "797                   3                    1        1    3              0   \n",
      "798                   3                    1        1    3              0   \n",
      "799                   1                    1        1    3              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 1      0  \n",
      "2                 1      0  \n",
      "3                 1      0  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "795               1      0  \n",
      "796               1      0  \n",
      "797               1      1  \n",
      "798               1      0  \n",
      "799               1      1  \n",
      "\n",
      "[800 rows x 21 columns]\n",
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0        0.60       0.272003                    1.00             0.75   \n",
      "1        0.15       0.245757                    0.25             0.50   \n",
      "2        0.30       0.172793                    0.75             1.00   \n",
      "3        0.20       0.137066                    1.00             0.25   \n",
      "4        1.00       0.712195                    0.50             1.00   \n",
      "..        ...            ...                     ...              ...   \n",
      "195      0.30       0.099828                    0.75             0.25   \n",
      "196      0.20       0.084370                    1.00             0.50   \n",
      "197      0.10       0.064033                    0.25             0.75   \n",
      "198      0.60       0.555548                    0.50             1.00   \n",
      "199      0.10       0.092477                    0.50             1.00   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.461538              0.25             0.5                1        3   \n",
      "1    0.400000              0.25             1.0                3        4   \n",
      "2    0.661538              0.25             0.5                3        3   \n",
      "3    0.415385              0.25             0.5                0        4   \n",
      "4    0.646154              0.25             0.5                3        4   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "195  0.400000              0.25             0.5                3        6   \n",
      "196  0.369231              0.25             0.5                1        4   \n",
      "197  0.600000              0.50             0.5                0        8   \n",
      "198  0.646154              1.00             0.5                0        4   \n",
      "199  0.646154              0.25             1.0                3        6   \n",
      "\n",
      "     credit_history  ...  employment  personal_status  other_parties  \\\n",
      "0                 3  ...           4                3              2   \n",
      "1                 3  ...           0                3              1   \n",
      "2                 3  ...           0                3              2   \n",
      "3                 1  ...           2                3              2   \n",
      "4                 3  ...           3                3              2   \n",
      "..              ...  ...         ...              ...            ...   \n",
      "195               3  ...           2                0              2   \n",
      "196               3  ...           0                0              2   \n",
      "197               1  ...           1                0              2   \n",
      "198               2  ...           3                3              2   \n",
      "199               3  ...           3                3              2   \n",
      "\n",
      "     property_magnitude  other_payment_plans  housing  job  own_telephone  \\\n",
      "0                     1                    1        1    0              1   \n",
      "1                     3                    1        2    1              0   \n",
      "2                     3                    1        1    1              1   \n",
      "3                     0                    1        1    1              0   \n",
      "4                     1                    1        1    0              1   \n",
      "..                  ...                  ...      ...  ...            ...   \n",
      "195                   3                    1        1    1              0   \n",
      "196                   3                    1        1    3              0   \n",
      "197                   1                    1        1    3              0   \n",
      "198                   0                    1        1    0              1   \n",
      "199                   2                    0        0    1              1   \n",
      "\n",
      "     foreign_worker  class  \n",
      "0                 1      1  \n",
      "1                 0      1  \n",
      "2                 1      1  \n",
      "3                 1      1  \n",
      "4                 1      1  \n",
      "..              ...    ...  \n",
      "195               1      1  \n",
      "196               1      0  \n",
      "197               1      1  \n",
      "198               1      0  \n",
      "199               1      1  \n",
      "\n",
      "[200 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#everything good with data except categorical to one hot needed \n",
    "credit_cat = ['checking_status', 'purpose', 'credit_history', 'savings_status', 'employment', 'personal_status', 'other_parties',\n",
    "             'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker', 'class']\n",
    "\n",
    "def extract_columns (df, cols):\n",
    "    return df.loc[:, cols]\n",
    "\n",
    "def get_onehot (df, cat_feat):\n",
    "    categories = extract_columns(df, cat_feat)\n",
    "    le = LabelEncoder()\n",
    "    return categories.apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "merged_credit = pd.concat([credit, credit_target], axis=1)\n",
    "merged_credit.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merged_credit_test = pd.concat([credit_test, credit_target_test], axis=1)\n",
    "merged_credit_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "one_hot_cols = get_onehot(merged_credit, credit_cat)\n",
    "credit_no_cat = merged_credit.drop(credit_cat, axis = 1) \n",
    "credit_no_cat = credit_no_cat.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x))) #normalize continuous data\n",
    "credit_final = pd.concat([credit_no_cat, one_hot_cols], axis=1)\n",
    "\n",
    "\n",
    "one_hot_cols_test = get_onehot(merged_credit_test, credit_cat)\n",
    "credit_test_no_cat = merged_credit_test.drop(credit_cat, axis=1)\n",
    "credit_test_no_cat = credit_test_no_cat.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "credit_test_final = pd.concat([credit_test_no_cat, one_hot_cols_test], axis=1)\n",
    "\n",
    "#le = LabelEncoder()\n",
    "\n",
    "#credit_target = le.fit_transform(credit_target)\n",
    "#credit_target_test = le.fit_transform(credit_target_test)\n",
    "\n",
    "print (credit_final)\n",
    "print (credit_test_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optimizer class implementing minibatch gradient descent for softmax regression. Can utilize either\n",
    "    gradient descent with momentum, or Adaptive Momentum Estimation (Adam), with optional L1 or L2\n",
    "    regularization.\n",
    "\"\"\"\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
    "\n",
    "\n",
    "# Shuffles the (x,y) instances, and outputs a list of minibatch_size sized (x,y) tuples\n",
    "def minibatch(x, y, minibatch_size):\n",
    "    x, y = shuffle(x, y)\n",
    "    minibatches = []\n",
    "    if not minibatch_size:\n",
    "        minibatches.append((x, y))\n",
    "    else:\n",
    "        for i in range(0, x.shape[0], minibatch_size):\n",
    "            x_mini = x[i:i+minibatch_size]\n",
    "            y_mini = y[i:i+minibatch_size]\n",
    "            minibatches.append((x_mini, y_mini))\n",
    "    return minibatches\n",
    "\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(y, yh):\n",
    "    B = np.where(yh.ravel() >= 0.5, 1, 0)\n",
    "    return np.mean(y.ravel() == B)\n",
    "\n",
    "\n",
    "# Returns the index of the maximum value in a list\n",
    "def argmax(lst):\n",
    "    return lst.index(max(lst))\n",
    "\n",
    "\n",
    "class GradientDescent:\n",
    "\n",
    "    \"\"\"\n",
    "    Class fields:\n",
    "       alphaa - learning rate of the optimizer\n",
    "       beta1 - momentum hyperparameter\n",
    "       max_iterations - gradient descent termination condition: maximum times iterated\n",
    "       max_no_change - gradient descent termination condition: maximum number of iterations\n",
    "                         without the validation error decreasing\n",
    "       minibatch_size - size of the minibatch to use (default value of 0 indicates use full batch)\n",
    "       cost_fn - optional cost function, if included optimizer will calculate and store the\n",
    "                    training and validation cost at each iteration\n",
    "       adaptive - if true, optimizer uses Adam (Adaptive Moment Estimation) rather than gradient\n",
    "                    descent with momentum\n",
    "       beta2 - 2nd hyperparameter for Adam (if using)\n",
    "       epsilon - 3rd hyperparameter for Adam (if using), just to avoid numerical issues\n",
    "       regularize - determines regularization used (if any): 0 indicates no regularization, 1 or 2\n",
    "                      indicate L1 or L2 regularization respectively\n",
    "       lambdaa - regularization coefficient if used\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(self, alphaa=0.01, beta1=0.9, max_iterations=1e4, max_no_change=20, minibatch_size=0,\n",
    "                 cost_fn=None, adaptive=False, beta2=0.999, epsilon=1e-8, regularize=0, lambdaa=0.1):\n",
    "\n",
    "        self.alphaa = alphaa\n",
    "        self.beta1 = beta1\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_no_change = max_no_change\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.cost_fn = cost_fn\n",
    "\n",
    "        self.adaptive = adaptive\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.regularize = regularize\n",
    "        self.lambdaa = lambdaa\n",
    "\n",
    "        self.accuracy_tr = []\n",
    "        self.accuracy_val = []\n",
    "        self.weight_history = []\n",
    "        if self.cost_fn:\n",
    "            self.cost_tr = []\n",
    "            self.cost_val = []\n",
    "\n",
    "    # Run method - delegates work to one of 2 helper methods, dependent on if Adam is being used or not\n",
    "    def run(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        if self.adaptive:\n",
    "            return self.adam(x_tr, y_tr, x_val, y_val, w)\n",
    "        else:\n",
    "            return self.momentum(x_tr, y_tr, x_val, y_val, w)\n",
    "\n",
    "    # Gradient Descent with Momentum\n",
    "    def momentum(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        t = 1\n",
    "        i = 0\n",
    "        delta_w = 0\n",
    "\n",
    "        self.accuracy_tr.append(accuracy(y_tr, softmax(np.dot(x_tr, w))))\n",
    "        self.accuracy_val.append(accuracy(y_val, softmax(np.dot(x_val, w))))\n",
    "        self.weight_history.append(w)\n",
    "\n",
    "        while i < self.max_no_change and t < self.max_iterations:\n",
    "            for (x_mini, y_mini) in minibatch(x_tr, y_tr, self.minibatch_size):\n",
    "                grad = self.gradient(x_mini, y_mini, w)\n",
    "                delta_w = (self.beta1 * delta_w) + ((1 - self.beta1) * grad)\n",
    "                w -= self.alphaa * delta_w\n",
    "\n",
    "            self.weight_history.append(w)\n",
    "            tr_pred = softmax(np.dot(x_tr, w))\n",
    "            pred = softmax(np.dot(x_val, w))\n",
    "            self.accuracy_tr.append(accuracy(y_tr, tr_pred))\n",
    "            self.accuracy_val.append(accuracy(y_val, pred))\n",
    "            if self.cost_fn:\n",
    "                self.cost_tr.append(self.cost_fn(y_tr, tr_pred))\n",
    "                self.cost_val.append(self.cost_fn(y_val, pred))\n",
    "\n",
    "            if not self.accuracy_val[-1] < self.accuracy_val[-2]:\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "            t += 1\n",
    "        return self.weight_history[argmax(self.accuracy_val)]\n",
    "\n",
    "    # Adaptive Moment Estimation\n",
    "    def adam(self, x_tr, y_tr, x_val, y_val, w):\n",
    "        t = 1\n",
    "        i = 0\n",
    "        m = 0\n",
    "        s = 0\n",
    "\n",
    "        self.accuracy_tr.append(accuracy(y_tr, softmax(np.dot(x_tr, w))))\n",
    "        self.accuracy_val.append(accuracy(y_val, softmax(np.dot(x_val, w))))\n",
    "        self.weight_history.append(w)\n",
    "\n",
    "        while i < self.max_no_change and t < self.max_iterations:\n",
    "            for (x_mini, y_mini) in minibatch(x_tr, y_tr, self.minibatch_size):\n",
    "                grad = self.gradient(x_mini, y_mini, w)\n",
    "                m = (self.beta1 * m) + ((1 - self.beta1) * grad)\n",
    "                s = (self.beta2 * s) + ((1 - self.beta2) * np.power(grad, 2))\n",
    "                mh = m / (1 - np.power(self.beta1, t))\n",
    "                sh = s / (1 - np.power(self.beta2, t))\n",
    "                w -= self.alphaa * mh * grad / (np.sqrt(sh) + self.epsilon)\n",
    "\n",
    "            self.weight_history.append(w)\n",
    "            tr_pred = softmax(np.dot(x_tr, w))\n",
    "            pred = softmax(np.dot(x_val, w))\n",
    "            self.accuracy_tr.append(accuracy(y_tr, tr_pred))\n",
    "            self.accuracy_val.append(accuracy(y_val, pred))\n",
    "            if self.cost_fn:\n",
    "                self.cost_tr.append(self.cost_fn(y_tr, tr_pred))\n",
    "                self.cost_val.append(self.cost_fn(y_val, pred))\n",
    "\n",
    "            if not self.accuracy_val[-1] < self.accuracy_val[-2]:\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "            t += 1\n",
    "        return self.weight_history[argmax(self.accuracy_val)]\n",
    "\n",
    "    # Helper method to calculate gradient (and add regularization penalty if any)\n",
    "    def gradient(self, x, y, w):\n",
    "        n, d = x.shape\n",
    "        yh = softmax(np.dot(x, w))\n",
    "\n",
    "        grad = np.dot(x.T, yh - y) / n\n",
    "        if self.regularize == 1:\n",
    "            grad[1:] += self.lambdaa * np.sign(w[1:])\n",
    "        elif self.regularize == 2:\n",
    "            grad[1:] += self.lambdaa * w[1:]\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from .._base import _BaseClassifier\n",
    "#from .._base import _BaseMultiClass\n",
    "\n",
    "\n",
    "class SoftmaxRegression(object):\n",
    "\n",
    "    \"\"\"Softmax regression classifier.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, max_iters=50,\n",
    "                 l2=0.0,\n",
    "                 minibatches=1,\n",
    "                 n_classes=None,\n",
    "                 random_seed=None):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.l2 = l2\n",
    "        self.minibatches = minibatches\n",
    "        self.n_classes = n_classes\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "\n",
    "    def fit(self, X, y, gd):\n",
    "        \n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "  \n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = np.max(y) + 1\n",
    "        self._n_features = X.shape[1]\n",
    "\n",
    "\n",
    "        \"\"\"Initialize weight coefficients.\"\"\"\n",
    "        np.random.seed(self.random_seed)\n",
    "        self.w_ = np.random.normal(loc=0.0, scale=0.01, size=(self._n_features, self.n_classes)).astype('float64')\n",
    "        self.cost_ = []\n",
    "\n",
    "        y_enc = self._one_hot(y=y, n_labels=self.n_classes, dtype=np.float)\n",
    "     \n",
    "        for i in range(self.max_iters):\n",
    "           \n",
    "            \n",
    "            #GRADIENT DESCENT line below (make sure to split X, y into training and validation sets)\n",
    "            \n",
    "            self._w = gd.run(X,y_enc,X,y_enc,self.w_)\n",
    "            \n",
    "            #COMMENT THE FOR LOOP BELOW\n",
    "\n",
    "            \"\"\" \n",
    "            for idx in self._yield_minibatches_idx(\n",
    "                    n_batches=self.minibatches,\n",
    "                    data_ary=y,\n",
    "                    shuffle=True):\n",
    "                # givens:\n",
    "                # w_ -> n_feat x n_classes\n",
    "                # b_  -> n_classes\n",
    "                \n",
    "                # net_input, softmax and diff -> n_samples x n_classes:\n",
    "                net = X[idx].dot(self.w_) #net_input\n",
    "                softm = self.softmax(net) \n",
    "                diff = softm - y_enc[idx]\n",
    "                mse = np.mean(diff, axis=0)\n",
    "\n",
    "                # gradient -> n_features x n_classes\n",
    "                grad = np.dot(X[idx].T, diff)\n",
    "                \n",
    "                # update in opp. direction of the cost gradient\n",
    "                self.w_ -= (self.eta * grad +\n",
    "                            self.eta * self.l2 * self.w_)  \n",
    "            \n",
    "            \"\"\"  \n",
    "            # compute cost of the whole epoch\n",
    "            net = X.dot(self.w_)\n",
    "            softm = self.softmax(net)\n",
    "            cross_ent = self.cross_entropy(output=softm, y_target=y_enc)\n",
    "            cost = self.cost(cross_ent)\n",
    "            self.cost_.append(cost)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        #Predict targets from X.\n",
    "\n",
    "        net = X.dot(self.w_)\n",
    "        probas = self.softmax(net)\n",
    "        return probas.argmax(axis=1)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
    "\n",
    "\n",
    "    def cross_entropy(self, output, y_target):\n",
    "        return - np.sum(np.log(output) * (y_target), axis=1)\n",
    "\n",
    "    def cost(self, cross_entropy):\n",
    "        L2_term = self.l2 * np.sum(self.w_ ** 2)\n",
    "        cross_entropy = cross_entropy + L2_term\n",
    "        return 0.5 * np.mean(cross_entropy)\n",
    "\n",
    "\n",
    "    def _one_hot(self, y, n_labels, dtype):\n",
    "        mat = np.zeros((len(y), n_labels))\n",
    "        for i, val in enumerate(y):\n",
    "            mat[i, val] = 1\n",
    "        return mat.astype(dtype)    \n",
    "    \n",
    "    def _yield_minibatches_idx(self, n_batches, data_ary, shuffle=True):\n",
    "            indices = np.arange(data_ary.shape[0])\n",
    "\n",
    "            if shuffle:\n",
    "                indices = np.random.permutation(indices)\n",
    "            if n_batches > 1:\n",
    "                remainder = data_ary.shape[0] % n_batches\n",
    "\n",
    "                if remainder:\n",
    "                    minis = np.array_split(indices[:-remainder], n_batches)\n",
    "                    minis[-1] = np.concatenate((minis[-1],\n",
    "                                                indices[-remainder:]),\n",
    "                                               axis=0)\n",
    "                else:\n",
    "                    minis = np.array_split(indices, n_batches)\n",
    "\n",
    "            else:\n",
    "                minis = (indices,)\n",
    "\n",
    "            for idx_batch in minis:\n",
    "                yield idx_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading Data\n",
    "\n",
    "#X = one_hot_cols.values\n",
    "#y = credit_target.values\n",
    "\n",
    "X = digits.values\n",
    "y = digits_target.values\n",
    "\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df = df.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "\n",
    "#standardize\n",
    "# X[:,0] = X[:,0] / np.amax(X[:,0])\n",
    "# X[:,1] = X[:,1] / np.amax(X[:,1])\n",
    "\n",
    "\n",
    "lr = SoftmaxRegression(learning_rate=0.00001, max_iters=250, minibatches=1, random_seed=0)\n",
    "gd = GradientDescent()\n",
    "lr.fit(df.to_numpy(), y, gd)\n",
    "\n",
    "# #X_plt = X[:, [0,1]]\n",
    "\n",
    "# #plot_decision_regions(X_plt, y, clf=lr)\n",
    "# #plt.title('Softmax Regression - Gradient Descent')\n",
    "# #plt.show()\n",
    "\n",
    "plt.plot(range(len(lr.cost_)), lr.cost_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5, 2, 8, 6, 6, 6, 6, 1, 0, 5, 8, 8, 7,\n",
       "       8, 4, 7, 5, 4, 9, 2, 9, 4, 7, 6, 8, 9, 4, 3, 1, 0, 1, 8, 6, 7, 7,\n",
       "       1, 0, 7, 6, 2, 1, 9, 6, 7, 9, 0, 0, 5, 1, 6, 3, 0, 2, 3, 4, 1, 9,\n",
       "       2, 6, 9, 1, 8, 3, 5, 1, 2, 8, 2, 2, 9, 7, 2, 3, 6, 0, 5, 3, 7, 5,\n",
       "       1, 2, 9, 9, 3, 1, 7, 7, 4, 8, 5, 8, 5, 5, 2, 5, 9, 0, 7, 1, 4, 7,\n",
       "       3, 4, 8, 9, 7, 9, 8, 2, 6, 5, 2, 5, 8, 4, 8, 7, 0, 6, 1, 5, 9, 9,\n",
       "       9, 5, 9, 9, 5, 7, 5, 6, 2, 8, 6, 9, 6, 1, 5, 1, 5, 9, 9, 1, 5, 3,\n",
       "       6, 1, 8, 9, 8, 7, 6, 7, 6, 5, 6, 0, 8, 8, 9, 8, 6, 1, 0, 4, 1, 6,\n",
       "       3, 8, 6, 7, 4, 5, 6, 3, 0, 3, 3, 3, 0, 7, 7, 5, 7, 8, 0, 7, 8, 9,\n",
       "       6, 4, 5, 0, 1, 4, 6, 4, 3, 3, 0, 9, 5, 9, 2, 1, 4, 2, 1, 6, 8, 9,\n",
       "       2, 4, 9, 3, 7, 6, 2, 3, 3, 1, 6, 9, 3, 6, 3, 2, 2, 0, 7, 6, 1, 1,\n",
       "       9, 7, 2, 7, 8, 5, 5, 7, 5, 2, 3, 7, 2, 7, 5, 5, 7, 0, 9, 1, 6, 5,\n",
       "       9, 7, 4, 3, 8, 0, 3, 6, 4, 6, 3, 2, 6, 8, 8, 8, 4, 6, 7, 5, 2, 4,\n",
       "       5, 3, 2, 4, 6, 9, 4, 5, 4, 3, 4, 6, 2, 9, 0, 1, 7, 2, 0, 9, 6, 0,\n",
       "       4, 2, 0, 7, 9, 8, 5, 4, 8, 2, 8, 4, 3, 7, 2, 6, 9, 1, 5, 1, 0, 8,\n",
       "       2, 1, 9, 5, 6, 8, 2, 7, 2, 1, 5, 1, 6, 4, 5, 0, 9, 4, 1, 1, 7, 0,\n",
       "       8, 9, 0, 5, 4, 3, 8, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_target_test.values[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 2 Class Labels: [2 8 2 6 6 7 1 9 8 5 2 8 6 6 6 6 1 0 5 8 8 7 8 4 7 5 4 9 2 9 4 7 6 8 9 4 3\n",
      " 1 0 1 8 6 7 7 9 0 7 6 2 1 9 6 7 9 0 0 9 1 6 3 0 2 3 4 1 9 7 6 9 1 8 3 5 1\n",
      " 2 1 2 2 9 7 2 3 6 0 5 3 7 5 1 2 9 9 3 1 7 7 4 8 5 8 5 5 2 5 9 0 7 1 4 7 3\n",
      " 4 8 9 7 7 8 0 1 9 2 5 8 4 1 7 0 6 1 5 9 9 9 5 9 9 5 7 5 6 2 8 6 9 6 1 5 1\n",
      " 5 9 9 1 5 3 6 1 8 9 7 7 6 7 6 5 6 0 8 8 9 3 6 1 0 7 1 6 3 8 6 7 4 9 6 3 0\n",
      " 3 3 3 0 7 7 5 7 8 0 7 8 9 6 4 5 0 1 4 6 4 3 3 0 9 5 9 3 9 4 7 1 6 8 9 2 4\n",
      " 9 3 7 6 2 3 3 1 6 9 3 6 3 3 2 0 7 6 1 1 3 7 2 7 1 5 5 7 5 2 2 7 2 7 5 5 7\n",
      " 0 9 1 6 5 9 7 4 3 8 0 3 6 4 6 3 2 6 8 8 8 4 6 7 5 2 4 5 3 2 4 6 9 4 5 4 3\n",
      " 4 6 2 9 0 6 7 2 0 9 6 0 4 2 0 7 5 8 5 7 8 2 8 4 3 7 2 6 5 9 5 1 0 8 2 5 9\n",
      " 5 6 8 2 7 2 1 5 1 6 4 5 0 9 4 1 1 7 0 8 9 0 5 4 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = lr.predict(digits_test.values)\n",
    "print('Last 2 Class Labels: %s' % y_pred[0:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.15534086 1.         ... 1.         0.         1.        ]\n",
      " [0.33333333 0.16950716 1.         ... 1.         0.         1.        ]\n",
      " [0.83333333 0.40208424 1.         ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.125      0.20798958 0.25       ... 3.         0.         1.        ]\n",
      " [0.25       0.10464611 0.5        ... 3.         0.         1.        ]\n",
      " [0.5        0.53500868 0.25       ... 3.         1.         1.        ]]\n",
      "     duration  credit_amount  installment_commitment  residence_since  \\\n",
      "0    0.500000       0.155341                    1.00             0.75   \n",
      "1    0.333333       0.169507                    1.00             0.25   \n",
      "2    0.833333       0.402084                    1.00             0.50   \n",
      "3    0.208333       0.068606                    0.50             0.50   \n",
      "4    0.083333       0.084347                    0.25             0.50   \n",
      "..        ...            ...                     ...              ...   \n",
      "795  0.166667       0.058728                    1.00             1.00   \n",
      "796  0.375000       0.212495                    1.00             0.50   \n",
      "797  0.125000       0.207990                    0.25             1.00   \n",
      "798  0.250000       0.104646                    0.50             0.50   \n",
      "799  0.500000       0.535009                    0.25             0.75   \n",
      "\n",
      "          age  existing_credits  num_dependents  checking_status  purpose  \\\n",
      "0    0.400000              0.25             0.5                0        4   \n",
      "1    0.360000              0.25             0.5                1        4   \n",
      "2    0.320000              0.25             0.5                0        4   \n",
      "3    0.333333              0.25             0.5                0        4   \n",
      "4    0.320000              0.50             0.5                3        6   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "795  0.640000              0.50             0.5                1        4   \n",
      "796  0.480000              0.25             1.0                0        0   \n",
      "797  0.853333              0.25             0.5                3        2   \n",
      "798  0.413333              0.50             0.5                0        3   \n",
      "799  0.413333              0.50             1.0                0        0   \n",
      "\n",
      "     credit_history  savings_status  employment  personal_status  \\\n",
      "0                 2               0           3                3   \n",
      "1                 3               2           2                0   \n",
      "2                 3               0           2                0   \n",
      "3                 0               0           0                2   \n",
      "4                 1               2           1                0   \n",
      "..              ...             ...         ...              ...   \n",
      "795               4               2           0                3   \n",
      "796               3               2           0                3   \n",
      "797               3               4           3                3   \n",
      "798               1               2           2                3   \n",
      "799               2               0           1                3   \n",
      "\n",
      "     other_parties  property_magnitude  other_payment_plans  housing  job  \\\n",
      "0                2                   2                    1        0    1   \n",
      "1                2                   1                    1        1    1   \n",
      "2                2                   1                    1        1    0   \n",
      "3                2                   1                    1        2    1   \n",
      "4                2                   0                    1        2    1   \n",
      "..             ...                 ...                  ...      ...  ...   \n",
      "795              2                   0                    0        1    1   \n",
      "796              2                   0                    1        1    1   \n",
      "797              2                   3                    1        1    3   \n",
      "798              2                   3                    1        1    3   \n",
      "799              2                   1                    1        1    3   \n",
      "\n",
      "     own_telephone  foreign_worker  \n",
      "0                0               1  \n",
      "1                0               1  \n",
      "2                0               1  \n",
      "3                0               1  \n",
      "4                1               1  \n",
      "..             ...             ...  \n",
      "795              0               1  \n",
      "796              1               1  \n",
      "797              0               1  \n",
      "798              0               1  \n",
      "799              1               1  \n",
      "\n",
      "[800 rows x 20 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Loading Data\n",
    "\n",
    "x_train = credit_final.loc[:,credit_final.columns != \"class\"]\n",
    "y_train = credit_final.loc[:,credit_final.columns == \"class\"]\n",
    "\n",
    "print (x_train.to_numpy())\n",
    "\n",
    "# df = pd.DataFrame(x_train)\n",
    "# df = df.transform(lambda x: x if (np.amax(x) == 0) else (x / np.amax(x)))\n",
    "\n",
    "lr2 = SoftmaxRegression(learning_rate=0.00001, max_iters=250, minibatches=1, random_seed=0)\n",
    "gd = GradientDescent()\n",
    "lr2.fit(x_train.to_numpy(), y_train.values.ravel(), gd)\n",
    "\n",
    "print (x_train)\n",
    "#X_plt = X[:, [0,1]]\n",
    "\n",
    "#plot_decision_regions(X_plt, y, clf=lr)\n",
    "#plt.title('Softmax Regression - Gradient Descent')\n",
    "#plt.show()\n",
    "\n",
    "plt.plot(range(len(lr2.cost_)), lr2.cost_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834     bad\n",
       "832     bad\n",
       "435     bad\n",
       "5      good\n",
       "769    good\n",
       "679    good\n",
       "722     bad\n",
       "215    good\n",
       "653     bad\n",
       "150    good\n",
       "Name: class, dtype: category\n",
       "Categories (2, object): [good, bad]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_target_test[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 2 Class Labels: [0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr2.predict(one_hot_cols_test.values)\n",
    "print('Last 2 Class Labels: %s' % y_pred[-100:])\n",
    "len(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Validation:\n",
    "    def cross_validate(self, data, k, model, gradient_obj, test_cols): \n",
    "        \n",
    "        train_col = None\n",
    "        \n",
    "        for c in test_cols:\n",
    "            if c in data:\n",
    "                train_col = c\n",
    "                break\n",
    "        \n",
    "        shuffled_data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "            \n",
    "        folds = np.array_split(shuffled_data, k)\n",
    "        \n",
    "        accuracy_sum = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            folds_to_train = folds.copy()\n",
    "            fold_to_test = folds_to_train[i]\n",
    "            del folds_to_train[i]\n",
    "            folds_to_train = pd.concat(folds_to_train, sort=False)\n",
    "            \n",
    "            x_train = folds_to_train.loc[:,folds_to_train.columns != train_col]\n",
    "            y_train = folds_to_train.loc[:,folds_to_train.columns == train_col]\n",
    "            \n",
    "            x_test = fold_to_test.loc[:,fold_to_test.columns != train_col]\n",
    "            y_test = fold_to_test.loc[:,fold_to_test.columns == train_col]\n",
    "            \n",
    "            model.fit(x_train, y_train.values.ravel(), gradient_obj)\n",
    "            predictions = model.predict(x_test.to_numpy())\n",
    "            accuracy_sum += accuracy_score(predictions, y_test.values.ravel())\n",
    "            \n",
    "        return accuracy_sum / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-f5ef1d6899e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-f5ef1d6899e3>\u001b[0m in \u001b[0;36mgrid_search\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     96\u001b[0m                           lambdaa=row[12])\n\u001b[0;32m     97\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m             \u001b[0mrun_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-f5ef1d6899e3>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     49\u001b[0m                                   \u001b[0madaptive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                                   lambdaa=self.lambdaa, minibatch_size=self.minibatch_size)\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-b5ef2d0ad154>\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(self, data, k, model, gradient_obj, test_cols)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfold_to_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfold_to_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrain_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0maccuracy_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-6531b37c9c42>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, gd)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m#GRADIENT DESCENT line below (make sure to split X, y into training and validation sets)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m#COMMENT THE FOR LOOP BELOW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-f67499bc9576>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, x_tr, y_tr, x_val, y_val, w)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Gradient Descent with Momentum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-f67499bc9576>\u001b[0m in \u001b[0;36mmomentum\u001b[1;34m(self, x_tr, y_tr, x_val, y_val, w)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_no_change\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_mini\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m                 \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mdelta_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdelta_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-f67499bc9576>\u001b[0m in \u001b[0;36mminibatch\u001b[1;34m(x, y, minibatch_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mx_mini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0my_mini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mminibatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_mini\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2781\u001b[0m             \u001b[1;31m# either we have a slice or we have a string that can be converted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2782\u001b[0m             \u001b[1;31m#  to a slice for partial-string date indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2783\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2785\u001b[0m         \u001b[1;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, slobj, axis, kind)\u001b[0m\n\u001b[0;32m   3612\u001b[0m         \"\"\"\n\u001b[0;32m   3613\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3614\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3615\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[0mnew_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set up grid testing\n",
    "\n",
    "\n",
    "# param_grid = [\n",
    "#   {'learning_rate': np.arange(0.00001, 0.0001, 0.00005), 'max_iters': [250], 'random_seed':[0],\n",
    "#   'alphaa': np.arange(0.001, 0.011, 0.01), 'beta1': np.arange(0.9, 0.99, 0.09), 'max_iterations': [1e4], 'max_no_change': np.arange(10,20,10), \n",
    "#   'adaptive': [False], 'beta2': np.arange(0.99, 0.999, 0.009), 'epsilon': np.arange(1e-9, 1e-8, 9e-9), 'minibatch_size': np.arange(1,10, 9),\n",
    "#   'regularize': [0,1,2], 'lambdaa': np.arange(0.01, 0.1, 0.09)}\n",
    "# ]\n",
    "\n",
    "\n",
    "#merge train and train targets, send to cross validation for each grid\n",
    "# print (digits_final)\n",
    "# print (credit_final)\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, learning_rate=0.01, max_iters=50, random_seed=0, alphaa=0.001, beta1=0.9, max_iterations=1e4, max_no_change=20,\n",
    "                 adaptive=False, beta2=0.999, epsilon=1e-8, minibatch_size=0, regularize=0, lambdaa=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iters = max_iters\n",
    "        self.random_seed = random_seed\n",
    "        self.alphaa = alphaa\n",
    "        self.beta1 = beta1\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_no_change = max_no_change\n",
    "        self.adaptive = adaptive\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.regularize = regularize\n",
    "        self.lambdaa = lambdaa\n",
    "        self.minibatch_size = minibatch_size    \n",
    "    \n",
    "#     def get_params(self, deep=True):\n",
    "#         # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "#         params = {'learning_rate': self.learning_rate, 'max_iters': self.max_iters, 'random_seed':self.random_seed,\n",
    "#                   'alphaa': self.alphaa, 'beta1': self.beta1, 'max_iterations': self.max_iterations, 'max_no_change': self.max_no_change, \n",
    "#                   'adaptive': self.adaptive, 'beta2':self.beta2, 'epsilon': self.epsilon, 'minibatch_size': self.minibatch_size,\n",
    "#                   'regularize': self.regularize, 'lambdaa': self.lambdaa}\n",
    "#         return params\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self,X):\n",
    "        self.lr = SoftmaxRegression(learning_rate=self.learning_rate, max_iters=self.max_iters, random_seed=self.random_seed)\n",
    "        self.gd = GradientDescent(alphaa=self.alphaa, max_iterations=self.max_iterations, max_no_change=self.max_no_change,\n",
    "                                  adaptive=self.adaptive, beta2=self.beta2, epsilon=self.epsilon, regularize=self.regularize,\n",
    "                                  lambdaa=self.lambdaa, minibatch_size=self.minibatch_size)\n",
    "        self.accuracy = cross.cross_validate(X, 5, self.lr, self.gd, ['target', 'class'])\n",
    "        print (self.accuracy)\n",
    "        return self.accuracy\n",
    "        \n",
    "    \n",
    "# def test_scorer(estimator, X):\n",
    "#     print (estimator.accuracy)\n",
    "#     return estimator.accuracy\n",
    "\n",
    "learning_rates = np.arange(0.00001, 0.0001, 0.00005)\n",
    "max_iters = [250]\n",
    "random_seed = [0]\n",
    "alphas = np.arange(0.001, 0.011, 0.01)\n",
    "beta1s = np.arange(0.9, 0.99, 0.09)\n",
    "max_iterations = [1e4]\n",
    "max_no_changes = np.arange(10,20,10)\n",
    "adaptives = [False]\n",
    "beta2s = np.arange(0.99, 0.999, 0.009)\n",
    "epsilons = np.arange(1e-9, 1e-8, 9e-9)\n",
    "minibatch_sizes = np.arange(1,10, 9)\n",
    "regularizes = [0,1,2]\n",
    "lambdas = np.arange(0.01, 0.1, 0.09)\n",
    "\n",
    "combos = np.array(np.meshgrid(learning_rates, max_iters, random_seed, alphas, beta1s, max_iterations, max_no_changes, adaptives, beta2s,\n",
    "               epsilons, minibatch_sizes, regularizes, lambdas)).T.reshape(-1, 13)\n",
    "\n",
    "cross = Cross_Validation()\n",
    "\n",
    "class GridSearcher:    \n",
    "    def grid_search(self, data, combinations):\n",
    "        t = None\n",
    "        max_accuracy = 0\n",
    "        min_time = 0\n",
    "\n",
    "        self.accuracies = []\n",
    "        self.train_times = []\n",
    "\n",
    "        for row in combos:\n",
    "            if t is None:\n",
    "                t = Tester(learning_rate=row[0], max_iters=int(row[1]), random_seed=int(row[2]), alphaa=row[3], beta1=row[4], max_iterations=int(row[5]),\n",
    "                          max_no_change=int(row[6]), adaptive=row[7], beta2=row[8], epsilon=row[9], minibatch_size=int(row[10]), regularize=int(row[11]),\n",
    "                          lambdaa=row[12])\n",
    "            else:\n",
    "                t.set_params(learning_rate=row[0], max_iters=int(row[1]), random_seed=int(row[2]), alphaa=row[3], beta1=row[4], max_iterations=int(row[5]),\n",
    "                          max_no_change=int(row[6]), adaptive=row[7], beta2=row[8], epsilon=row[9], minibatch_size=int(row[10]), regularize=int(row[11]),\n",
    "                          lambdaa=row[12])\n",
    "            start_time = time.time()\n",
    "            accuracy = t.fit(data)\n",
    "            run_time = time.time() - start_time\n",
    "            \n",
    "            self.accuracies.append(accuracy)\n",
    "            self.train_times.append(run_time)\n",
    "        \n",
    "g = GridSearcher()\n",
    "g.grid_search(digits_final, comb)\n",
    "\n",
    "\n",
    "\n",
    "# def tester_scorer_credit(estimator, X):\n",
    "#     error = cross.cross_validate(X, 5, estimator.lr, estimator.gd, 'class')\n",
    "#     return error\n",
    "\n",
    "# cv = [(slice(None), slice(None))] # dont use grid search cross validation, want to use our own\n",
    "# gs = GridSearchCV(estimator=Tester(), param_grid=param_grid, \n",
    "#                   scoring=test_scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "# gs.fit(digits_final)\n",
    "#get best hyper parameters, then run test data using them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([77.75337529, 76.56331205]), 'std_fit_time': array([0., 0.]), 'mean_score_time': array([0., 0.]), 'std_score_time': array([0., 0.]), 'param_learning_rate': masked_array(data=[1e-05, 6e-05],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 1e-05}, {'learning_rate': 6e-05}], 'split0_test_score': array([0.94850707, 0.94850707]), 'mean_test_score': array([0.94850707, 0.94850707]), 'std_test_score': array([0., 0.]), 'rank_test_score': array([1, 1])}\n",
      "{'learning_rate': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print (gs.cv_results_)\n",
    "print (gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
